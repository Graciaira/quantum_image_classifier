{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from numpy import loadtxt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 4)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "X_4 = loadtxt('C:/Users/user/quantum_image_classifier/Image Preprocessing/Dataset One-vs-All/x_train_4features_' + str(0) + '.txt', delimiter=',')\n",
    "\n",
    "X_test_4 = loadtxt('C:/Users/user/quantum_image_classifier/Image Preprocessing/Dataset One-vs-All/x_test_4features_' + str(0) + '.txt', delimiter=',')\n",
    "\n",
    "X_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_4 = np.zeros((X_4.shape[0],))\n",
    "Y_4[:int(X_4.shape[0]/2)] = 1\n",
    "Y_4[int(X_4.shape[0]/2):] = -1\n",
    "\n",
    "Y_test_4 = np.zeros((X_test_4.shape[0],))\n",
    "Y_test_4[:int(X_test_4.shape[0]/2)] = 1\n",
    "Y_test_4[int(X_test_4.shape[0]/2):] = -1\n",
    "\n",
    "Y_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ..., -1., -1., -1.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_L6_F4(input_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(2, input_dim=input_dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer=SGD(lr=0.01), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def nn_model_L12_F4(input_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(2, input_dim=input_dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer=SGD(lr=η), metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "η = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_L6_F4 = nn_model_L6_F4(4)\n",
    "model_L6_F4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 806 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "806/806 [==============================] - 1s 843us/step - loss: 0.9932 - acc: 0.0000e+00 - val_loss: 1.4431 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.9359 - acc: 0.0000e+00 - val_loss: 1.5810 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9286 - acc: 0.0000e+00 - val_loss: 1.5568 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.9206 - acc: 0.0000e+00 - val_loss: 1.6409 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9055 - acc: 0.0000e+00 - val_loss: 1.4977 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.8756 - acc: 0.0000e+00 - val_loss: 1.5807 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.8142 - acc: 0.0099 - val_loss: 1.5895 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.7307 - acc: 0.0496 - val_loss: 1.5172 - val_acc: 0.0743\n",
      "Epoch 9/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.6577 - acc: 0.1129 - val_loss: 1.6499 - val_acc: 0.1089\n",
      "Epoch 10/100\n",
      "806/806 [==============================] - 0s 47us/step - loss: 0.6106 - acc: 0.4392 - val_loss: 1.4999 - val_acc: 0.1634\n",
      "Epoch 11/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.5812 - acc: 0.5149 - val_loss: 1.7146 - val_acc: 0.1584\n",
      "Epoch 12/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.5569 - acc: 0.6526 - val_loss: 1.4643 - val_acc: 0.2277\n",
      "Epoch 13/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.5343 - acc: 0.6340 - val_loss: 1.3975 - val_acc: 0.2574\n",
      "Epoch 14/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.5143 - acc: 0.6414 - val_loss: 1.4830 - val_acc: 0.2624\n",
      "Epoch 15/100\n",
      "806/806 [==============================] - 0s 38us/step - loss: 0.4946 - acc: 0.6898 - val_loss: 1.3484 - val_acc: 0.2772\n",
      "Epoch 16/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.4755 - acc: 0.6998 - val_loss: 1.1575 - val_acc: 0.3168\n",
      "Epoch 17/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.4529 - acc: 0.6886 - val_loss: 1.0839 - val_acc: 0.3366\n",
      "Epoch 18/100\n",
      "806/806 [==============================] - 0s 38us/step - loss: 0.4298 - acc: 0.7084 - val_loss: 1.0658 - val_acc: 0.3515\n",
      "Epoch 19/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.4079 - acc: 0.7246 - val_loss: 0.9952 - val_acc: 0.3614\n",
      "Epoch 20/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.3871 - acc: 0.7382 - val_loss: 0.7879 - val_acc: 0.3812\n",
      "Epoch 21/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.3682 - acc: 0.7407 - val_loss: 0.6716 - val_acc: 0.4010\n",
      "Epoch 22/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.3511 - acc: 0.7556 - val_loss: 0.6765 - val_acc: 0.3960\n",
      "Epoch 23/100\n",
      "806/806 [==============================] - 0s 38us/step - loss: 0.3396 - acc: 0.7680 - val_loss: 0.3952 - val_acc: 0.4406\n",
      "Epoch 24/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.3302 - acc: 0.7481 - val_loss: 0.4572 - val_acc: 0.4257\n",
      "Epoch 25/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.3180 - acc: 0.7829 - val_loss: 0.4760 - val_acc: 0.4257\n",
      "Epoch 26/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.3115 - acc: 0.7928 - val_loss: 0.3472 - val_acc: 0.7822\n",
      "Epoch 27/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.3054 - acc: 0.8102 - val_loss: 0.3664 - val_acc: 0.7970\n",
      "Epoch 28/100\n",
      "806/806 [==============================] - 0s 38us/step - loss: 0.3018 - acc: 0.8151 - val_loss: 0.2656 - val_acc: 0.8416\n",
      "Epoch 29/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.2966 - acc: 0.8213 - val_loss: 0.2541 - val_acc: 0.8416\n",
      "Epoch 30/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.2963 - acc: 0.8238 - val_loss: 0.3798 - val_acc: 0.8119\n",
      "Epoch 31/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.2934 - acc: 0.8300 - val_loss: 0.3211 - val_acc: 0.8267\n",
      "Epoch 32/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.2899 - acc: 0.8300 - val_loss: 0.3754 - val_acc: 0.8218\n",
      "Epoch 33/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.2879 - acc: 0.8325 - val_loss: 0.2829 - val_acc: 0.8564\n",
      "Epoch 34/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.2854 - acc: 0.8350 - val_loss: 0.2981 - val_acc: 0.8515\n",
      "Epoch 35/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.2834 - acc: 0.8288 - val_loss: 0.3786 - val_acc: 0.8317\n",
      "Epoch 36/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.2847 - acc: 0.8350 - val_loss: 0.3380 - val_acc: 0.8465\n",
      "Epoch 37/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.2809 - acc: 0.8387 - val_loss: 0.3904 - val_acc: 0.8267\n",
      "Epoch 38/100\n",
      "806/806 [==============================] - 0s 47us/step - loss: 0.2834 - acc: 0.8437 - val_loss: 0.2564 - val_acc: 0.8614\n",
      "Epoch 39/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2824 - acc: 0.8337 - val_loss: 0.3658 - val_acc: 0.8416\n",
      "Epoch 40/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2816 - acc: 0.8400 - val_loss: 0.3927 - val_acc: 0.8366\n",
      "Epoch 41/100\n",
      "806/806 [==============================] - 0s 38us/step - loss: 0.2804 - acc: 0.8400 - val_loss: 0.3496 - val_acc: 0.8465\n",
      "Epoch 42/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.2774 - acc: 0.8412 - val_loss: 0.2046 - val_acc: 0.8960\n",
      "Epoch 43/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.2793 - acc: 0.8412 - val_loss: 0.3138 - val_acc: 0.8515\n",
      "Epoch 44/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.2785 - acc: 0.8449 - val_loss: 0.3088 - val_acc: 0.8564\n",
      "Epoch 45/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.2742 - acc: 0.8412 - val_loss: 0.3332 - val_acc: 0.8515\n",
      "Epoch 46/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.2739 - acc: 0.8400 - val_loss: 0.4025 - val_acc: 0.8416\n",
      "Epoch 47/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.2743 - acc: 0.8462 - val_loss: 0.3402 - val_acc: 0.8515\n",
      "Epoch 48/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.2779 - acc: 0.8424 - val_loss: 0.3640 - val_acc: 0.8465\n",
      "Epoch 49/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.2750 - acc: 0.8474 - val_loss: 0.2851 - val_acc: 0.8713\n",
      "Epoch 50/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.2749 - acc: 0.8437 - val_loss: 0.3576 - val_acc: 0.8465\n",
      "Epoch 51/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.2707 - acc: 0.8511 - val_loss: 0.3741 - val_acc: 0.8465\n",
      "Epoch 52/100\n",
      "806/806 [==============================] - 0s 38us/step - loss: 0.2725 - acc: 0.8449 - val_loss: 0.3572 - val_acc: 0.8465\n",
      "Epoch 53/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.2738 - acc: 0.8486 - val_loss: 0.3695 - val_acc: 0.8465\n",
      "Epoch 54/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.2708 - acc: 0.8474 - val_loss: 0.3435 - val_acc: 0.8515\n",
      "Epoch 55/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.2718 - acc: 0.8412 - val_loss: 0.3533 - val_acc: 0.8515\n",
      "Epoch 56/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.2705 - acc: 0.8524 - val_loss: 0.3314 - val_acc: 0.8663\n",
      "Epoch 57/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.2711 - acc: 0.8486 - val_loss: 0.4526 - val_acc: 0.8317\n",
      "Epoch 58/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.2719 - acc: 0.8548 - val_loss: 0.4408 - val_acc: 0.8366\n",
      "Epoch 59/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.2745 - acc: 0.8536 - val_loss: 0.3612 - val_acc: 0.8564\n",
      "Epoch 60/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2693 - acc: 0.8524 - val_loss: 0.3293 - val_acc: 0.8663\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806/806 [==============================] - 0s 41us/step - loss: 0.2690 - acc: 0.8524 - val_loss: 0.3395 - val_acc: 0.8663\n",
      "Epoch 62/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.2688 - acc: 0.8511 - val_loss: 0.3275 - val_acc: 0.8663\n",
      "Epoch 63/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.2677 - acc: 0.8561 - val_loss: 0.3560 - val_acc: 0.8564\n",
      "Epoch 64/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.2672 - acc: 0.8511 - val_loss: 0.3466 - val_acc: 0.8663\n",
      "Epoch 65/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2677 - acc: 0.8511 - val_loss: 0.3141 - val_acc: 0.8663\n",
      "Epoch 66/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.2669 - acc: 0.8499 - val_loss: 0.4122 - val_acc: 0.8465\n",
      "Epoch 67/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2687 - acc: 0.8524 - val_loss: 0.3153 - val_acc: 0.8663\n",
      "Epoch 68/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2673 - acc: 0.8536 - val_loss: 0.2308 - val_acc: 0.8861\n",
      "Epoch 69/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.2678 - acc: 0.8511 - val_loss: 0.4551 - val_acc: 0.8366\n",
      "Epoch 70/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2689 - acc: 0.8499 - val_loss: 0.2977 - val_acc: 0.8762\n",
      "Epoch 71/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.2682 - acc: 0.8424 - val_loss: 0.3669 - val_acc: 0.8614\n",
      "Epoch 72/100\n",
      "806/806 [==============================] - 0s 53us/step - loss: 0.2652 - acc: 0.8524 - val_loss: 0.3108 - val_acc: 0.8663\n",
      "Epoch 73/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2656 - acc: 0.8499 - val_loss: 0.3230 - val_acc: 0.8663\n",
      "Epoch 74/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.2643 - acc: 0.8536 - val_loss: 0.3566 - val_acc: 0.8614\n",
      "Epoch 75/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.2643 - acc: 0.8536 - val_loss: 0.2937 - val_acc: 0.8663\n",
      "Epoch 76/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.2629 - acc: 0.8610 - val_loss: 0.3635 - val_acc: 0.8614\n",
      "Epoch 77/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.2631 - acc: 0.8536 - val_loss: 0.4222 - val_acc: 0.8416\n",
      "Epoch 78/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.2680 - acc: 0.8573 - val_loss: 0.3451 - val_acc: 0.8614\n",
      "Epoch 79/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2630 - acc: 0.8536 - val_loss: 0.4399 - val_acc: 0.8416\n",
      "Epoch 80/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.2653 - acc: 0.8536 - val_loss: 0.2981 - val_acc: 0.8713\n",
      "Epoch 81/100\n",
      "806/806 [==============================] - 0s 47us/step - loss: 0.2633 - acc: 0.8499 - val_loss: 0.3673 - val_acc: 0.8515\n",
      "Epoch 82/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.2643 - acc: 0.8486 - val_loss: 0.3415 - val_acc: 0.8663\n",
      "Epoch 83/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2633 - acc: 0.8536 - val_loss: 0.3429 - val_acc: 0.8614\n",
      "Epoch 84/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.2601 - acc: 0.8573 - val_loss: 0.3517 - val_acc: 0.8564\n",
      "Epoch 85/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2596 - acc: 0.8586 - val_loss: 0.3283 - val_acc: 0.8663\n",
      "Epoch 86/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2600 - acc: 0.8586 - val_loss: 0.3064 - val_acc: 0.8663\n",
      "Epoch 87/100\n",
      "806/806 [==============================] - 0s 47us/step - loss: 0.2603 - acc: 0.8548 - val_loss: 0.3503 - val_acc: 0.8564\n",
      "Epoch 88/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2589 - acc: 0.8598 - val_loss: 0.2213 - val_acc: 0.8960\n",
      "Epoch 89/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.2606 - acc: 0.8598 - val_loss: 0.3073 - val_acc: 0.8762\n",
      "Epoch 90/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2609 - acc: 0.8524 - val_loss: 0.3521 - val_acc: 0.8564\n",
      "Epoch 91/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.2602 - acc: 0.8548 - val_loss: 0.3921 - val_acc: 0.8465\n",
      "Epoch 92/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.2607 - acc: 0.8586 - val_loss: 0.4192 - val_acc: 0.8416\n",
      "Epoch 93/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.2590 - acc: 0.8586 - val_loss: 0.3232 - val_acc: 0.8663\n",
      "Epoch 94/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.2628 - acc: 0.8524 - val_loss: 0.3852 - val_acc: 0.8465\n",
      "Epoch 95/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.2582 - acc: 0.8598 - val_loss: 0.3533 - val_acc: 0.8515\n",
      "Epoch 96/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.2574 - acc: 0.8548 - val_loss: 0.3265 - val_acc: 0.8614\n",
      "Epoch 97/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.2559 - acc: 0.8573 - val_loss: 0.3447 - val_acc: 0.8564\n",
      "Epoch 98/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.2566 - acc: 0.8586 - val_loss: 0.3495 - val_acc: 0.8564\n",
      "Epoch 99/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.2551 - acc: 0.8586 - val_loss: 0.3484 - val_acc: 0.8564\n",
      "Epoch 100/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.2576 - acc: 0.8598 - val_loss: 0.4356 - val_acc: 0.8366\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "history_callback_L6_F4 = model_L6_F4.fit(X_4, Y_4, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21e3675fd88>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iter_history = np.linspace(1, 100, 100, dtype=int)\n",
    "\n",
    "plt.plot(iter_history, history_callback_L6_F4.history['acc'])\n",
    "plt.plot(iter_history, history_callback_L6_F4.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_L12_F4 = nn_model_L12_F4(4)\n",
    "model_L12_F4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 806 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "806/806 [==============================] - 0s 61us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.5791 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "806/806 [==============================] - 0s 53us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.6041 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "806/806 [==============================] - 0s 55us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.5423 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "806/806 [==============================] - 0s 47us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.5323 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9387 - acc: 0.0000e+00 - val_loss: 1.5425 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5932 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.6189 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.6087 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.6045 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.5544 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9377 - acc: 0.0000e+00 - val_loss: 1.5572 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.5709 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.5286 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "806/806 [==============================] - 0s 53us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.5106 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "806/806 [==============================] - 0s 55us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5124 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.5547 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.5616 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9378 - acc: 0.0000e+00 - val_loss: 1.6294 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9390 - acc: 0.0000e+00 - val_loss: 1.5711 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "806/806 [==============================] - 0s 51us/step - loss: 0.9378 - acc: 0.0000e+00 - val_loss: 1.5447 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "806/806 [==============================] - 0s 55us/step - loss: 0.9378 - acc: 0.0000e+00 - val_loss: 1.5227 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "806/806 [==============================] - 0s 51us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.5092 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "806/806 [==============================] - 0s 55us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.5128 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.5951 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.5234 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "806/806 [==============================] - 0s 55us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.5537 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "806/806 [==============================] - 0s 58us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.6030 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "806/806 [==============================] - 0s 64us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.5721 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5416 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.5399 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.5982 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.5864 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.6047 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "806/806 [==============================] - 0s 47us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.5757 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.6168 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.6461 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "806/806 [==============================] - 0s 47us/step - loss: 0.9389 - acc: 0.0000e+00 - val_loss: 1.5487 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "806/806 [==============================] - 0s 61us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.4875 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "806/806 [==============================] - 0s 64us/step - loss: 0.9388 - acc: 0.0000e+00 - val_loss: 1.5356 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "806/806 [==============================] - 0s 67us/step - loss: 0.9376 - acc: 0.0000e+00 - val_loss: 1.5211 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "806/806 [==============================] - 0s 57us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5750 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.5488 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "806/806 [==============================] - 0s 47us/step - loss: 0.9378 - acc: 0.0000e+00 - val_loss: 1.6192 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.6298 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "806/806 [==============================] - 0s 53us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.5931 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "806/806 [==============================] - 0s 56us/step - loss: 0.9378 - acc: 0.0000e+00 - val_loss: 1.5490 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "806/806 [==============================] - 0s 55us/step - loss: 0.9378 - acc: 0.0000e+00 - val_loss: 1.5915 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "806/806 [==============================] - 0s 56us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5935 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9378 - acc: 0.0000e+00 - val_loss: 1.5665 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5729 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5624 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5839 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.6186 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "806/806 [==============================] - 0s 51us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.6141 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "806/806 [==============================] - 0s 74us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.5996 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "806/806 [==============================] - 0s 62us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.5744 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "806/806 [==============================] - 0s 62us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.6237 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806/806 [==============================] - 0s 57us/step - loss: 0.9377 - acc: 0.0000e+00 - val_loss: 1.5684 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5640 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "806/806 [==============================] - 0s 51us/step - loss: 0.9376 - acc: 0.0000e+00 - val_loss: 1.5842 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9389 - acc: 0.0000e+00 - val_loss: 1.6408 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.5629 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "806/806 [==============================] - 0s 55us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.5689 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.6190 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.5940 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "806/806 [==============================] - 0s 55us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.5911 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "806/806 [==============================] - 0s 61us/step - loss: 0.9378 - acc: 0.0000e+00 - val_loss: 1.5692 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "806/806 [==============================] - 0s 62us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.5232 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "806/806 [==============================] - 0s 61us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.6139 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.5642 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9377 - acc: 0.0000e+00 - val_loss: 1.6311 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "806/806 [==============================] - 0s 57us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.6005 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "806/806 [==============================] - 0s 56us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5653 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.5205 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "806/806 [==============================] - 0s 56us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.5614 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "806/806 [==============================] - 0s 53us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.6228 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "806/806 [==============================] - 0s 51us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.5957 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "806/806 [==============================] - 0s 56us/step - loss: 0.9386 - acc: 0.0000e+00 - val_loss: 1.5648 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "806/806 [==============================] - 0s 60us/step - loss: 0.9375 - acc: 0.0000e+00 - val_loss: 1.6196 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "806/806 [==============================] - 0s 62us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.6510 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "806/806 [==============================] - 0s 66us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.6208 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "806/806 [==============================] - 0s 64us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.6436 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "806/806 [==============================] - 0s 58us/step - loss: 0.9387 - acc: 0.0000e+00 - val_loss: 1.6274 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "806/806 [==============================] - 0s 51us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.4945 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.5031 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "806/806 [==============================] - 0s 55us/step - loss: 0.9388 - acc: 0.0000e+00 - val_loss: 1.5184 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "806/806 [==============================] - 0s 47us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.5210 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "806/806 [==============================] - 0s 51us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5293 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "806/806 [==============================] - 0s 51us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.5398 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "806/806 [==============================] - 0s 51us/step - loss: 0.9378 - acc: 0.0000e+00 - val_loss: 1.5470 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.5529 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.5922 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9378 - acc: 0.0000e+00 - val_loss: 1.5564 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.5266 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5748 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "806/806 [==============================] - 0s 63us/step - loss: 0.9378 - acc: 0.0000e+00 - val_loss: 1.5971 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "806/806 [==============================] - 0s 63us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.5814 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "806/806 [==============================] - 0s 58us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.6043 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.6161 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.6253 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "history_callback_L12_F4 = model_L12_F4.fit(X_4, Y_4, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
