{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from numpy import loadtxt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "X_4 = loadtxt('C:/Users/user/quantum_image_classifier/Image Preprocessing/Dataset One-vs-All/x_train_4features_' + str(0) + '.txt', delimiter=',')\n",
    "\n",
    "X_test_4 = loadtxt('C:/Users/user/quantum_image_classifier/Image Preprocessing/Dataset One-vs-All/x_test_4features_' + str(0) + '.txt', delimiter=',')\n",
    "\n",
    "X_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_4 = np.zeros((X_4.shape[0],))\n",
    "Y_4[:int(X_4.shape[0]/2)] = 1\n",
    "Y_4[int(X_4.shape[0]/2):] = -1\n",
    "\n",
    "Y_test_4 = np.zeros((X_test_4.shape[0],))\n",
    "Y_test_4[:int(X_test_4.shape[0]/2)] = 1\n",
    "Y_test_4[int(X_test_4.shape[0]/2):] = -1\n",
    "\n",
    "Y_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "X_8 = loadtxt('C:/Users/user/quantum_image_classifier/Image Preprocessing/Dataset One-vs-All/x_train_8features_' + str(0) + '.txt', delimiter=',')\n",
    "\n",
    "X_test_8 = loadtxt('C:/Users/user/quantum_image_classifier/Image Preprocessing/Dataset One-vs-All/x_test_8features_' + str(0) + '.txt', delimiter=',')\n",
    "\n",
    "X_8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_8 = np.zeros((X_8.shape[0],))\n",
    "Y_8[:int(X_8.shape[0]/2)] = 1\n",
    "Y_8[int(X_8.shape[0]/2):] = -1\n",
    "\n",
    "Y_test_8 = np.zeros((X_test_8.shape[0],))\n",
    "Y_test_8[:int(X_test_8.shape[0]/2)] = 1\n",
    "Y_test_8[int(X_test_8.shape[0]/2):] = -1\n",
    "\n",
    "Y_8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "η = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model_L6_F4(input_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(2, input_dim=input_dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer=SGD(lr=η), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def nn_model_L12_F4(input_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(2, input_dim=input_dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer=RMSprop(lr=η), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def nn_model_L6_F8(input_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(3, input_dim=input_dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer=RMSprop(lr=η), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def nn_model_L12_F8(input_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(3, input_dim=input_dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer=RMSprop(lr=η), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_94 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_L6_F4 = nn_model_L6_F4(4)\n",
    "model_L6_F4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_100 (Dense)            (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 73\n",
      "Trainable params: 73\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_L12_F4 = nn_model_L12_F4(4)\n",
    "model_L12_F4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_112 (Dense)            (None, 3)                 27        \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 55\n",
      "Trainable params: 55\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_L6_F8 = nn_model_L6_F8(8)\n",
    "model_L6_F8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_116 (Dense)            (None, 3)                 27        \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 110\n",
      "Trainable params: 110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_L12_F8 = nn_model_L12_F8(8)\n",
    "model_L12_F8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 806 samples, validate on 202 samples\n",
      "Epoch 1/100\n",
      "806/806 [==============================] - 1s 1ms/step - loss: 0.9624 - acc: 0.0000e+00 - val_loss: 1.4029 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.9409 - acc: 0.0000e+00 - val_loss: 1.4686 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9399 - acc: 0.0000e+00 - val_loss: 1.4645 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9391 - acc: 0.0000e+00 - val_loss: 1.5283 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "806/806 [==============================] - 0s 60us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.5792 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "806/806 [==============================] - 0s 55us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5869 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "806/806 [==============================] - 0s 38us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.6078 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9390 - acc: 0.0000e+00 - val_loss: 1.6458 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5727 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.5487 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9386 - acc: 0.0000e+00 - val_loss: 1.5051 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.5482 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.9391 - acc: 0.0000e+00 - val_loss: 1.5495 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9378 - acc: 0.0000e+00 - val_loss: 1.4481 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5650 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5959 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.6344 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9389 - acc: 0.0000e+00 - val_loss: 1.5848 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.4979 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.9388 - acc: 0.0000e+00 - val_loss: 1.5843 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "806/806 [==============================] - 0s 51us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.5152 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5136 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.5522 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.6150 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.9387 - acc: 0.0000e+00 - val_loss: 1.6599 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9396 - acc: 0.0000e+00 - val_loss: 1.5891 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5467 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.5052 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9386 - acc: 0.0000e+00 - val_loss: 1.4739 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9386 - acc: 0.0000e+00 - val_loss: 1.4900 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9387 - acc: 0.0000e+00 - val_loss: 1.5957 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "806/806 [==============================] - 0s 52us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5953 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.5605 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "806/806 [==============================] - 0s 40us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5638 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5362 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5696 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5163 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5208 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9389 - acc: 0.0000e+00 - val_loss: 1.4734 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "806/806 [==============================] - 0s 37us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.5212 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5996 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "806/806 [==============================] - 0s 38us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.6222 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "806/806 [==============================] - 0s 38us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.5795 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.6122 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9390 - acc: 0.0000e+00 - val_loss: 1.5450 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.4968 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "806/806 [==============================] - 0s 38us/step - loss: 0.9388 - acc: 0.0000e+00 - val_loss: 1.5430 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.5150 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.4915 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.5086 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.5557 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9387 - acc: 0.0000e+00 - val_loss: 1.5789 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.6192 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.5783 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "806/806 [==============================] - 0s 51us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5252 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.5697 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.6107 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806/806 [==============================] - 0s 45us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5828 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9387 - acc: 0.0000e+00 - val_loss: 1.6253 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.5784 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.5807 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.6076 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.5469 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9375 - acc: 0.0000e+00 - val_loss: 1.6140 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9376 - acc: 0.0000e+00 - val_loss: 1.5889 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9388 - acc: 0.0000e+00 - val_loss: 1.6044 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "806/806 [==============================] - 0s 47us/step - loss: 0.9373 - acc: 0.0000e+00 - val_loss: 1.4515 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.5576 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9389 - acc: 0.0000e+00 - val_loss: 1.5608 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5175 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.6194 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "806/806 [==============================] - 0s 51us/step - loss: 0.9388 - acc: 0.0000e+00 - val_loss: 1.5911 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5178 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "806/806 [==============================] - 0s 53us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5702 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9388 - acc: 0.0000e+00 - val_loss: 1.6381 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "806/806 [==============================] - 0s 51us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.6020 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "806/806 [==============================] - 0s 47us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.5731 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "806/806 [==============================] - 0s 53us/step - loss: 0.9386 - acc: 0.0000e+00 - val_loss: 1.5911 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "806/806 [==============================] - 0s 58us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.6244 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.9386 - acc: 0.0000e+00 - val_loss: 1.6347 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "806/806 [==============================] - 0s 42us/step - loss: 0.9387 - acc: 0.0000e+00 - val_loss: 1.6013 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "806/806 [==============================] - 0s 41us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5554 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.5704 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "806/806 [==============================] - 0s 48us/step - loss: 0.9380 - acc: 0.0000e+00 - val_loss: 1.5515 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.5416 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9376 - acc: 0.0000e+00 - val_loss: 1.5134 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.5589 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "806/806 [==============================] - 0s 43us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.4839 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9386 - acc: 0.0000e+00 - val_loss: 1.5421 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "806/806 [==============================] - 0s 53us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.5673 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5216 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "806/806 [==============================] - 0s 53us/step - loss: 0.9382 - acc: 0.0000e+00 - val_loss: 1.6146 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9384 - acc: 0.0000e+00 - val_loss: 1.5894 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9383 - acc: 0.0000e+00 - val_loss: 1.6537 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9379 - acc: 0.0000e+00 - val_loss: 1.5118 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9385 - acc: 0.0000e+00 - val_loss: 1.5128 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "806/806 [==============================] - 0s 50us/step - loss: 0.9377 - acc: 0.0000e+00 - val_loss: 1.6246 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9386 - acc: 0.0000e+00 - val_loss: 1.5858 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "806/806 [==============================] - 0s 46us/step - loss: 0.9381 - acc: 0.0000e+00 - val_loss: 1.5617 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "806/806 [==============================] - 0s 45us/step - loss: 0.9377 - acc: 0.0000e+00 - val_loss: 1.5397 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "\n",
    "history_callback_L6_F4 = model_L6_F4.fit(X_4, Y_4, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [1.4893077611923218,\n",
       "  1.5418874025344849,\n",
       "  1.6562172174453735,\n",
       "  1.645118242443198,\n",
       "  1.62294340723812,\n",
       "  1.4623194932937622,\n",
       "  1.5185675621032715,\n",
       "  1.5858418941497803,\n",
       "  1.6567186117172241,\n",
       "  1.6266047954559326,\n",
       "  1.4766714572906494,\n",
       "  1.6091033279305638,\n",
       "  1.6522265731698216,\n",
       "  1.5681592226028442,\n",
       "  1.6107173025017918,\n",
       "  1.5744280815124512,\n",
       "  1.4661113023757935,\n",
       "  1.657010561168784,\n",
       "  1.7010575591927708,\n",
       "  1.6859893798828125,\n",
       "  1.4947283267974854,\n",
       "  1.5981581211090088,\n",
       "  1.5052568912506104,\n",
       "  1.6499513387680054,\n",
       "  1.5998808145523071,\n",
       "  1.6613705158233643,\n",
       "  1.4711618423461914,\n",
       "  1.735374921619302,\n",
       "  1.585485816001892,\n",
       "  1.462056040763855,\n",
       "  1.456932783126831,\n",
       "  1.533462643623352,\n",
       "  1.6456414520150364,\n",
       "  1.529189944267273,\n",
       "  1.5557492971420288,\n",
       "  1.4917902946472168,\n",
       "  1.567827582359314,\n",
       "  1.5528429746627808,\n",
       "  1.5766693353652954,\n",
       "  1.671980857849121,\n",
       "  1.4199022054672241,\n",
       "  1.512959599494934,\n",
       "  1.6011109293097316,\n",
       "  1.6241710186004639,\n",
       "  1.5328503847122192,\n",
       "  1.5905979871749878,\n",
       "  1.5655001401901245,\n",
       "  1.59003484249115,\n",
       "  1.675139302074319,\n",
       "  1.632554292678833,\n",
       "  1.6529887914657593,\n",
       "  1.5705256462097168,\n",
       "  1.5181212425231934,\n",
       "  1.6245402038687526,\n",
       "  1.510647177696228,\n",
       "  1.5215295553207397,\n",
       "  1.5063655376434326,\n",
       "  1.7005510330200195,\n",
       "  1.5424363613128662,\n",
       "  1.5551944971084595,\n",
       "  1.572288990020752,\n",
       "  1.5748941898345947,\n",
       "  1.6342872381210327,\n",
       "  1.7149335204964817,\n",
       "  1.586912751197815,\n",
       "  1.5691114664077759,\n",
       "  1.7019363641738892,\n",
       "  1.4433870315551758,\n",
       "  1.755151623546487,\n",
       "  1.4724457263946533,\n",
       "  1.5458576679229736,\n",
       "  1.6329195499420166,\n",
       "  1.4925743341445923,\n",
       "  1.461591362953186,\n",
       "  1.4945210218429565,\n",
       "  1.5692763328552246,\n",
       "  1.5653045177459717,\n",
       "  1.6069178640252293,\n",
       "  1.5962108373641968,\n",
       "  1.5914095640182495,\n",
       "  1.6058846771126927,\n",
       "  1.618888026416892,\n",
       "  1.715532660484314,\n",
       "  1.5414990186691284,\n",
       "  1.5525200366973877,\n",
       "  1.468371033668518,\n",
       "  1.4960696697235107,\n",
       "  1.5327459573745728,\n",
       "  1.4946993589401245,\n",
       "  1.4757118225097656,\n",
       "  1.5156173706054688,\n",
       "  1.7026337326163112,\n",
       "  1.5259190797805786,\n",
       "  1.6662421285515965,\n",
       "  1.638334035873413,\n",
       "  1.5741666555404663,\n",
       "  1.5990387201309204,\n",
       "  1.6454668045043945,\n",
       "  1.4675087928771973,\n",
       "  1.4668374061584473],\n",
       " 'val_acc': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'loss': [0.9474455891708582,\n",
       "  0.9399145022219523,\n",
       "  0.9396762942557891,\n",
       "  0.9391339884206615,\n",
       "  0.94061015838429,\n",
       "  0.9410288112039306,\n",
       "  0.9408892588343277,\n",
       "  0.9397615262355757,\n",
       "  0.936021044887325,\n",
       "  0.9406729133490002,\n",
       "  0.9388531239393627,\n",
       "  0.9414299905448043,\n",
       "  0.9388134226609697,\n",
       "  0.9399403895692849,\n",
       "  0.9405604035919417,\n",
       "  0.9391778034548606,\n",
       "  0.9392171749110257,\n",
       "  0.9393559181069027,\n",
       "  0.9401742347120943,\n",
       "  0.941877435661723,\n",
       "  0.9393367918194375,\n",
       "  0.9394272132487805,\n",
       "  0.9393129483346017,\n",
       "  0.9395434047388971,\n",
       "  0.9395161291801604,\n",
       "  0.9395696312263053,\n",
       "  0.939300219710944,\n",
       "  0.9391398528965176,\n",
       "  0.9396259780261416,\n",
       "  0.9399191475387838,\n",
       "  0.9404030056212735,\n",
       "  0.9396604783185954,\n",
       "  0.9407244771349224,\n",
       "  0.9393287586515062,\n",
       "  0.939719704629174,\n",
       "  0.9396578182949322,\n",
       "  0.9398312487318261,\n",
       "  0.9402883730218665,\n",
       "  0.9389058965311453,\n",
       "  0.9398617164668611,\n",
       "  0.9373159790157385,\n",
       "  0.9408132717863797,\n",
       "  0.939954837705598,\n",
       "  0.9396167671118422,\n",
       "  0.9393051272586321,\n",
       "  0.9400747933103784,\n",
       "  0.9393627451312158,\n",
       "  0.9395926452747941,\n",
       "  0.9388376685880846,\n",
       "  0.9389543474164258,\n",
       "  0.9398212168116131,\n",
       "  0.9398668324089524,\n",
       "  0.9381219058415434,\n",
       "  0.9393745653386744,\n",
       "  0.9387892537909761,\n",
       "  0.9396248591449066,\n",
       "  0.9392509614267657,\n",
       "  0.9389311058941313,\n",
       "  0.9392660329714603,\n",
       "  0.9400579589176414,\n",
       "  0.9388954808043487,\n",
       "  0.9405553629321437,\n",
       "  0.9399708252095111,\n",
       "  0.9384684522749472,\n",
       "  0.939583612730722,\n",
       "  0.9382113277468432,\n",
       "  0.9390100759844626,\n",
       "  0.9386546064547214,\n",
       "  0.9376286784413435,\n",
       "  0.939089526313706,\n",
       "  0.9403086628570746,\n",
       "  0.9394704013249419,\n",
       "  0.9388065904600744,\n",
       "  0.940174659783432,\n",
       "  0.9390631588753636,\n",
       "  0.9391561961055689,\n",
       "  0.9392281934877779,\n",
       "  0.9391130952917909,\n",
       "  0.9402134769016105,\n",
       "  0.9392258578139558,\n",
       "  0.9397098504875789,\n",
       "  0.9392167848925437,\n",
       "  0.9389287864895671,\n",
       "  0.9397037866393626,\n",
       "  0.9392522422610678,\n",
       "  0.9397727987606531,\n",
       "  0.9393069690865263,\n",
       "  0.9395515367055945,\n",
       "  0.9390955305572775,\n",
       "  0.9400826068433283,\n",
       "  0.9390587040567516,\n",
       "  0.9381437125631953,\n",
       "  0.9403336533245911,\n",
       "  0.9385266722579748,\n",
       "  0.940261570898534,\n",
       "  0.9389963209185351,\n",
       "  0.9404070355164502,\n",
       "  0.9394841040334394,\n",
       "  0.9392868806943112,\n",
       "  0.9384602317147456],\n",
       " 'acc': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_callback_L6_F4.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
