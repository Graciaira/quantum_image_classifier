{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train[:, 0:27, 0:27]\n",
    "x_test = x_test[:, 0:27, 0:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flatten = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])/255.0\n",
    "x_test_flatten = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 729) (60000,)\n",
      "(10000, 729) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_flatten.shape, y_train.shape)\n",
    "print(x_test_flatten.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5923, 729)\n",
      "(6742, 729)\n",
      "(5958, 729)\n",
      "(6131, 729)\n",
      "(5842, 729)\n",
      "(5421, 729)\n",
      "(5918, 729)\n",
      "(6265, 729)\n",
      "(5851, 729)\n",
      "(5949, 729)\n"
     ]
    }
   ],
   "source": [
    "x_train_0 = x_train_flatten[y_train == 0]\n",
    "x_train_1 = x_train_flatten[y_train == 1]\n",
    "x_train_2 = x_train_flatten[y_train == 2]\n",
    "x_train_3 = x_train_flatten[y_train == 3]\n",
    "x_train_4 = x_train_flatten[y_train == 4]\n",
    "x_train_5 = x_train_flatten[y_train == 5]\n",
    "x_train_6 = x_train_flatten[y_train == 6]\n",
    "x_train_7 = x_train_flatten[y_train == 7]\n",
    "x_train_8 = x_train_flatten[y_train == 8]\n",
    "x_train_9 = x_train_flatten[y_train == 9]\n",
    "\n",
    "x_train_list = [x_train_0, x_train_1, x_train_2, x_train_3, x_train_4, x_train_5, x_train_6, x_train_7, x_train_8, x_train_9]\n",
    "\n",
    "print(x_train_0.shape)\n",
    "print(x_train_1.shape)\n",
    "print(x_train_2.shape)\n",
    "print(x_train_3.shape)\n",
    "print(x_train_4.shape)\n",
    "print(x_train_5.shape)\n",
    "print(x_train_6.shape)\n",
    "print(x_train_7.shape)\n",
    "print(x_train_8.shape)\n",
    "print(x_train_9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(980, 729)\n",
      "(1135, 729)\n",
      "(1032, 729)\n",
      "(1010, 729)\n",
      "(982, 729)\n",
      "(892, 729)\n",
      "(958, 729)\n",
      "(1028, 729)\n",
      "(974, 729)\n",
      "(1009, 729)\n"
     ]
    }
   ],
   "source": [
    "x_test_0 = x_test_flatten[y_test == 0]\n",
    "x_test_1 = x_test_flatten[y_test == 1]\n",
    "x_test_2 = x_test_flatten[y_test == 2]\n",
    "x_test_3 = x_test_flatten[y_test == 3]\n",
    "x_test_4 = x_test_flatten[y_test == 4]\n",
    "x_test_5 = x_test_flatten[y_test == 5]\n",
    "x_test_6 = x_test_flatten[y_test == 6]\n",
    "x_test_7 = x_test_flatten[y_test == 7]\n",
    "x_test_8 = x_test_flatten[y_test == 8]\n",
    "x_test_9 = x_test_flatten[y_test == 9]\n",
    "\n",
    "x_test_list = [x_test_0, x_test_1, x_test_2, x_test_3, x_test_4, x_test_5, x_test_6, x_test_7, x_test_8, x_test_9]\n",
    "\n",
    "print(x_test_0.shape)\n",
    "print(x_test_1.shape)\n",
    "print(x_test_2.shape)\n",
    "print(x_test_3.shape)\n",
    "print(x_test_4.shape)\n",
    "print(x_test_5.shape)\n",
    "print(x_test_6.shape)\n",
    "print(x_test_7.shape)\n",
    "print(x_test_8.shape)\n",
    "print(x_test_9.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the dataset\n",
    "\n",
    "Output: X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 729), (800,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train_sample_per_class = 200\n",
    "n_class = 4\n",
    "\n",
    "X_train = x_train_list[0][:n_train_sample_per_class, :]\n",
    "Y_train = np.zeros((X_train.shape[0]*n_class,), dtype=int)\n",
    "\n",
    "for i in range(n_class-1):\n",
    "    X_train = np.concatenate((X_train, x_train_list[i+1][:n_train_sample_per_class, :]), axis=0)\n",
    "    Y_train[(i+1)*n_train_sample_per_class:(i+2)*n_train_sample_per_class] = i+1\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 729), (200,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_test_sample_per_class = int(0.25*n_train_sample_per_class)\n",
    "\n",
    "X_test = x_test_list[0][:n_test_sample_per_class, :]\n",
    "Y_test = np.zeros((X_test.shape[0]*n_class,), dtype=int)\n",
    "\n",
    "for i in range(n_class-1):\n",
    "    X_test = np.concatenate((X_test, x_test_list[i+1][:n_test_sample_per_class, :]), axis=0)\n",
    "    Y_test[(i+1)*n_test_sample_per_class:(i+2)*n_test_sample_per_class] = i+1\n",
    "\n",
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 27, 27), (200, 27, 27))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 27, 27)\n",
    "X_test = X_test.reshape(X_test.shape[0], 27, 27)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_dict = []\n",
    "for i in range(np.unique(Y_train).shape[0]):\n",
    "    temp_Y = np.zeros(Y_train.shape)\n",
    "    \n",
    "    temp_Y[Y_train == i] = 0  # positive class\n",
    "    temp_Y[Y_train != i] = 1  # negative class\n",
    "    temp_Y = to_categorical(temp_Y)\n",
    "    Y_train_dict += [('Y' + str(i), temp_Y)]\n",
    "    \n",
    "Y_train_dict = dict(Y_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_dict = []\n",
    "for i in range(np.unique(Y_test).shape[0]):\n",
    "    temp_Y = np.zeros(Y_test.shape)\n",
    "    \n",
    "    temp_Y[Y_test == i] = 0  # positive class\n",
    "    temp_Y[Y_test != i] = 1  # negative class\n",
    "    temp_Y = to_categorical(temp_Y)\n",
    "    Y_test_dict += [('Y' + str(i), temp_Y)]\n",
    "    \n",
    "Y_test_dict = dict(Y_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 2), (200, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_dict['Y1'].shape, Y_test_dict['Y0'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer, GradientDescentOptimizer\n",
    "\n",
    "qml.enable_tape()\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set a random seed\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output labels as quantum state vectors\n",
    "def density_matrix(state):\n",
    "    \"\"\"Calculates the density matrix representation of a state.\n",
    "\n",
    "    Args:\n",
    "        state (array[complex]): array representing a quantum state vector\n",
    "\n",
    "    Returns:\n",
    "        dm: (array[complex]): array representing the density matrix\n",
    "    \"\"\"\n",
    "    return state * np.conj(state).T\n",
    "\n",
    "\n",
    "label_0 = [[1], [0]]\n",
    "label_1 = [[0], [1]]\n",
    "state_labels = [label_0, label_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 2\n",
    "dev_fc = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "\n",
    "@qml.qnode(dev_fc)\n",
    "def q_fc(params, inputs):\n",
    "    \"\"\"A variational quantum circuit representing the DRC.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        inputs = [x, y]\n",
    "        x (array[float]): 1-d input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    \n",
    "    # layer iteration\n",
    "    for l in range(len(params[0])):\n",
    "        # qubit iteration\n",
    "        for q in range(n_qubits):\n",
    "            # gate iteration\n",
    "            for g in range(int(len(inputs)/3)):\n",
    "                qml.Rot(*(params[0][l][3*g:3*(g+1)] * inputs[3*g:3*(g+1)] + params[1][l][3*g:3*(g+1)]), wires=q)\n",
    "    \n",
    "    return [qml.expval(qml.Hermitian(density_matrix(state_labels[i]), wires=[i])) for i in range(n_qubits)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_conv = qml.device(\"default.qubit\", wires=9)\n",
    "\n",
    "\n",
    "@qml.qnode(dev_conv)\n",
    "def q_conv(conv_params, inputs):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier + Conv.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    # layer iteration\n",
    "    for l in range(len(conv_params[0])):\n",
    "        # RY layer\n",
    "        # height iteration\n",
    "        for i in range(3):\n",
    "            # width iteration\n",
    "            for j in range(3):\n",
    "                qml.RY((conv_params[0][l][3*i+j] * inputs[i, j] + conv_params[1][l][3*i+j]), wires=(3*i+j))\n",
    "    \n",
    "        # entangling layer\n",
    "        for i in range(9):\n",
    "            if i != (9-1):\n",
    "                qml.CNOT(wires=[i, i+1])\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0) @ qml.PauliZ(1) @ qml.PauliZ(2) @ qml.PauliZ(3) @ qml.PauliZ(4) @ qml.PauliZ(5) @ qml.PauliZ(6) @ qml.PauliZ(7) @ qml.PauliZ(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((2, 1, 9))\n",
    "q_conv(a, X_train[0, 0:3, 0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((2, 1, 9))\n",
    "q_fc(a, X_train[0, 0, 0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image, size = 27 x 27\n",
    "X = tf.keras.Input(shape=(27,27), name='Input_Layer')\n",
    "\n",
    "\n",
    "# Specs for Conv\n",
    "c_filter = 3\n",
    "c_strides = 2\n",
    "\n",
    "\n",
    "# First Quantum Conv Layer, trainable params = 18*L, output size = 13 x 13\n",
    "num_conv_layer_1 = 2\n",
    "q_conv_layer_1 = qml.qnn.KerasLayer(q_conv, {\"conv_params\": (2, num_conv_layer_1, 9)}, output_dim=(1), name='Quantum_Conv_Layer_1')\n",
    "size_1 = int(1+(X.shape[1]-c_filter)/c_strides)\n",
    "q_conv_layer_1_list = []\n",
    "# height iteration\n",
    "for i in range(size_1):\n",
    "    # width iteration\n",
    "    for j in range(size_1):\n",
    "        temp = q_conv_layer_1(X[:, 2*i:2*(i+1)+1, 2*j:2*(j+1)+1])\n",
    "        temp = tf.keras.layers.Reshape((1,))(temp)\n",
    "        q_conv_layer_1_list += [temp]\n",
    "concat_layer_1 = tf.keras.layers.Concatenate(axis=1)(q_conv_layer_1_list)\n",
    "reshape_layer_1 = tf.keras.layers.Reshape((size_1, size_1))(concat_layer_1)\n",
    "\n",
    "\n",
    "# Second Quantum Conv Layer, trainable params = 18*L, output size = 6 x 6\n",
    "num_conv_layer_2 = 2\n",
    "q_conv_layer_2 = qml.qnn.KerasLayer(q_conv, {\"conv_params\": (2, num_conv_layer_2, 9)}, output_dim=(1), name='Quantum_Conv_Layer_2')\n",
    "size_2 = int(1+(reshape_layer_1.shape[1]-c_filter)/c_strides)\n",
    "q_conv_layer_2_list = []\n",
    "# height iteration\n",
    "for i in range(size_2):\n",
    "    # width iteration\n",
    "    for j in range(size_2):\n",
    "        temp = q_conv_layer_2(reshape_layer_1[:, 2*i:2*(i+1)+1, 2*j:2*(j+1)+1])\n",
    "        temp = tf.keras.layers.Reshape((1,))(temp)\n",
    "        q_conv_layer_2_list += [temp]\n",
    "concat_layer_2 = tf.keras.layers.Concatenate(axis=1)(q_conv_layer_2_list)\n",
    "reshape_layer_2 = tf.keras.layers.Reshape((size_2, size_2, 1))(concat_layer_2)\n",
    "\n",
    "\n",
    "# Max Pooling Layer, output size = 9\n",
    "max_pool_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, name='Max_Pool_Layer')(reshape_layer_2)\n",
    "\n",
    "model = tf.keras.Model(inputs=X, outputs=max_pool_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "qconv_1_weights = np.array([[[ 0.30478922,  0.24122563,  1.2013984 ,  0.8962295 ,\n",
    "           2.155613  ,  1.808066  , -0.6777786 , -1.3539367 ,\n",
    "           0.46882528],\n",
    "         [ 0.10804682,  0.4899469 , -1.4487113 ,  0.18007451,\n",
    "           0.21117014, -0.07102177,  0.22456087,  0.19595939,\n",
    "           0.620559  ]],\n",
    " \n",
    "        [[ 0.08490325, -0.46300295,  0.88712513,  0.21560192,\n",
    "           0.68917143, -1.3093163 ,  1.0160891 , -0.17013887,\n",
    "           0.09957722],\n",
    "         [ 0.08793638, -0.0810757 , -0.3338206 ,  0.5029927 ,\n",
    "           0.46003294,  0.47570366, -0.18548904, -0.2648427 ,\n",
    "          -0.0655445 ]]])\n",
    "\n",
    "qconv_2_weights = np.array([[[ 2.7642950e-01,  2.3297124e+00, -7.7425838e-01,  4.8847955e-01,\n",
    "           4.3419965e-02, -3.3615255e-01, -1.0063299e+00,  2.2314610e+00,\n",
    "           9.1715485e-01],\n",
    "         [-4.1352111e-01,  3.0436099e-02, -1.2301649e+00,  1.7263293e-03,\n",
    "          -1.5698449e-01,  4.4744748e-01,  1.2136365e+00,  2.7647603e-01,\n",
    "           1.0283145e+00]],\n",
    " \n",
    "        [[-3.3875754e-01,  1.0402726e+00, -4.2845064e-01,  7.4869722e-02,\n",
    "           3.8802050e-02,  3.3155876e-01, -7.6660907e-01,  3.3909407e-01,\n",
    "           3.5294789e-01],\n",
    "         [ 6.6214994e-02, -1.3985926e-01,  9.4863945e-01, -1.1182010e-01,\n",
    "           2.7276468e-01,  3.9622694e-01,  3.1741151e-01, -2.2376621e-01,\n",
    "           3.0038670e-01]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qconv_1 = tf.keras.Model(inputs=X, outputs=reshape_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You called `set_weights(weights)` on layer \"Quantum_Conv_Layer_1\" with a weight list of length 1, but the layer was expecting 0 weights. Provided weights: [tensor([[[ 0.30478922,  0.24122563,  1.2013984 , ...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-f6c75ebad474>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_qconv_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreshape_layer_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_qconv_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Quantum_Conv_Layer_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mqconv_1_weights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_qconv_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreshape_layer_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel_qconv_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Quantum_Conv_Layer_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mqconv_1_weights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexpected_num_weights\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       raise ValueError(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           \u001b[1;34m'You called `set_weights(weights)` on layer \"%s\" '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m           \u001b[1;34m'with a weight list of length %s, but the layer was '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You called `set_weights(weights)` on layer \"Quantum_Conv_Layer_1\" with a weight list of length 1, but the layer was expecting 0 weights. Provided weights: [tensor([[[ 0.30478922,  0.24122563,  1.2013984 , ..."
     ]
    }
   ],
   "source": [
    "model_qconv_1 = tf.keras.Model(inputs=X, outputs=reshape_layer_1)\n",
    "model_qconv_1.get_layer('Quantum_Conv_Layer_1').set_weights([qconv_1_weights])\n",
    "\n",
    "model_qconv_2 = tf.keras.Model(inputs=X, outputs=reshape_layer_2)\n",
    "model_qconv_2.get_layer('Quantum_Conv_Layer_1').set_weights([qconv_1_weights])\n",
    "model_qconv_2.get_layer('Quantum_Conv_Layer_2').set_weights(qconv_2_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'model_1/Quantum_Conv_Layer_1/conv_params:0' shape=(2, 2, 9) dtype=float32, numpy=\n",
       " array([[[ 0.30478922,  0.24122563,  1.2013984 ,  0.8962295 ,\n",
       "           2.155613  ,  1.808066  , -0.6777786 , -1.3539367 ,\n",
       "           0.46882528],\n",
       "         [ 0.10804682,  0.4899469 , -1.4487113 ,  0.18007451,\n",
       "           0.21117014, -0.07102177,  0.22456087,  0.19595939,\n",
       "           0.620559  ]],\n",
       " \n",
       "        [[ 0.08490325, -0.46300295,  0.88712513,  0.21560192,\n",
       "           0.68917143, -1.3093163 ,  1.0160891 , -0.17013887,\n",
       "           0.09957722],\n",
       "         [ 0.08793638, -0.0810757 , -0.3338206 ,  0.5029927 ,\n",
       "           0.46003294,  0.47570366, -0.18548904, -0.2648427 ,\n",
       "          -0.0655445 ]]], dtype=float32)>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_qconv_1.get_layer('Quantum_Conv_Layer_1').weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.984375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.process_time()\n",
    "img_after_qconv_1 = model_qconv_1(X_train[0:5])\n",
    "print(time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1deecda77c0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_after_qconv_1[4], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y_train_dict)):\n",
    "    new_key = model.layers[len(model.layers)-4+i].name\n",
    "    old_key = \"Y\" + str(i)\n",
    "    \n",
    "    Y_train_dict[new_key] = Y_train_dict.pop(old_key)\n",
    "    Y_test_dict[new_key] = Y_test_dict.pop(old_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weights': array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_1': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_2': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_3': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weights': array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_1': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_2': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_3': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       " array([[-0.04429247, -0.00021604],\n",
       "        [-0.04427836, -0.00021929],\n",
       "        [-0.04437302, -0.00019746],\n",
       "        [-0.04439379, -0.00019267],\n",
       "        [-0.04422718, -0.0002311 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       " array([[-0.01929011,  0.00302043],\n",
       "        [-0.01917738,  0.00304499],\n",
       "        [-0.01926376,  0.00302617],\n",
       "        [-0.0191524 ,  0.00305044],\n",
       "        [-0.01924417,  0.00303044]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       " array([[0.09997694, 0.00027629],\n",
       "        [0.10011356, 0.00027084],\n",
       "        [0.10038836, 0.00025988],\n",
       "        [0.10036632, 0.00026076],\n",
       "        [0.10005108, 0.00027333]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       " array([[-0.0051364 ,  0.0018303 ],\n",
       "        [-0.00514253,  0.00180795],\n",
       "        [-0.00509635,  0.00197641],\n",
       "        [-0.0050894 ,  0.00200177],\n",
       "        [-0.00515911,  0.00174747]], dtype=float32)>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[0:5, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weights': 'mse', 'class_weights_1': 'mse', 'class_weights_2': 'mse', 'class_weights_3': 'mse'}\n"
     ]
    }
   ],
   "source": [
    "losses = {\n",
    "    model.layers[len(model.layers)-4+0].name: \"mse\",\n",
    "    model.layers[len(model.layers)-4+1].name: \"mse\",\n",
    "    model.layers[len(model.layers)-4+2].name: \"mse\",\n",
    "    model.layers[len(model.layers)-4+3].name: \"mse\"\n",
    "}\n",
    "\n",
    "#lossWeights = {\"Y0\": 1.0, \"Y1\": 1.0, \"Y2\": 1.0, \"Y3\": 1.0}\n",
    "\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "model.compile(opt, loss=losses, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(X_train, Y_train_dict, epochs=10, batch_size=32, validation_data=(X_test, Y_test_dict), verbose=1, initial_epoch=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2222222222222223"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1L QConv1, 1L QConv2, 1L QFC, no entangler at all\n",
    "# 1 epoch = ... jam\n",
    "8000/(60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.322222222222222"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "26360/(60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'model/Quantum_Conv_Layer_1/conv_params:0' shape=(2, 2, 9) dtype=float32, numpy=\n",
       " array([[[ 0.30478922,  0.24122563,  1.2013984 ,  0.8962295 ,\n",
       "           2.155613  ,  1.808066  , -0.6777786 , -1.3539367 ,\n",
       "           0.46882528],\n",
       "         [ 0.10804682,  0.4899469 , -1.4487113 ,  0.18007451,\n",
       "           0.21117014, -0.07102177,  0.22456087,  0.19595939,\n",
       "           0.620559  ]],\n",
       " \n",
       "        [[ 0.08490325, -0.46300295,  0.88712513,  0.21560192,\n",
       "           0.68917143, -1.3093163 ,  1.0160891 , -0.17013887,\n",
       "           0.09957722],\n",
       "         [ 0.08793638, -0.0810757 , -0.3338206 ,  0.5029927 ,\n",
       "           0.46003294,  0.47570366, -0.18548904, -0.2648427 ,\n",
       "          -0.0655445 ]]], dtype=float32)>,\n",
       " <tf.Variable 'model/Quantum_Conv_Layer_2/conv_params:0' shape=(2, 2, 9) dtype=float32, numpy=\n",
       " array([[[ 2.7642950e-01,  2.3297124e+00, -7.7425838e-01,  4.8847955e-01,\n",
       "           4.3419965e-02, -3.3615255e-01, -1.0063299e+00,  2.2314610e+00,\n",
       "           9.1715485e-01],\n",
       "         [-4.1352111e-01,  3.0436099e-02, -1.2301649e+00,  1.7263293e-03,\n",
       "          -1.5698449e-01,  4.4744748e-01,  1.2136365e+00,  2.7647603e-01,\n",
       "           1.0283145e+00]],\n",
       " \n",
       "        [[-3.3875754e-01,  1.0402726e+00, -4.2845064e-01,  7.4869722e-02,\n",
       "           3.8802050e-02,  3.3155876e-01, -7.6660907e-01,  3.3909407e-01,\n",
       "           3.5294789e-01],\n",
       "         [ 6.6214994e-02, -1.3985926e-01,  9.4863945e-01, -1.1182010e-01,\n",
       "           2.7276468e-01,  3.9622694e-01,  3.1741151e-01, -2.2376621e-01,\n",
       "           3.0038670e-01]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[-0.05643808, -0.3834348 ,  1.3783973 ,  1.8028375 ,\n",
       "           2.4020152 ,  3.265065  ,  0.04925077,  0.18717681,\n",
       "          -0.15576944]],\n",
       " \n",
       "        [[ 0.0552775 ,  0.83352816,  0.51252973,  0.67993635,\n",
       "           1.538679  ,  0.5075311 ,  1.462727  ,  0.28211135,\n",
       "          -0.18711801]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_1/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[ 0.5008777 , -1.3495312 , -0.5218247 ,  1.51395   ,\n",
       "           0.70898056,  1.331641  ,  0.75333315,  1.1442982 ,\n",
       "          -0.283115  ]],\n",
       " \n",
       "        [[ 0.23336929,  1.3037012 , -0.16543525, -0.8135664 ,\n",
       "           0.5298867 , -0.08688857, -0.40758485,  1.3480728 ,\n",
       "          -0.06701605]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_2/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[ 0.20852552, -0.92169833,  0.20204262, -1.4812163 ,\n",
       "           0.00889985, -1.5283754 , -0.8842213 , -2.125618  ,\n",
       "          -0.2756645 ]],\n",
       " \n",
       "        [[ 0.19089271, -1.2583857 , -0.05586167, -0.65264225,\n",
       "           0.72431535, -0.6168651 , -0.59993476, -2.472832  ,\n",
       "           0.120191  ]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_3/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[-0.30617303,  0.06194295, -0.42034343, -1.888615  ,\n",
       "          -2.2937555 ,  0.68672144,  1.2960382 , -1.1311744 ,\n",
       "          -0.19152352]],\n",
       " \n",
       "        [[-0.12496919, -0.75718635, -0.21456823, -0.07930091,\n",
       "          -0.44249678, -0.28310478,  0.76265246, -1.462515  ,\n",
       "           0.08680444]]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[0.9889597, 1.064973 ]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1.0520185, 1.0743465]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1.0430095, 1.0347432]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1.0084324, 1.0561559]], dtype=float32)>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_6_epoch_weights = model.weights\n",
    "first_6_epoch_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.9413223266601562,\n",
       "  0.5048812627792358,\n",
       "  0.4011978209018707,\n",
       "  0.347080796957016,\n",
       "  0.31995534896850586,\n",
       "  0.29129528999328613],\n",
       " 'class_weights_loss': [0.2251260131597519,\n",
       "  0.1090371310710907,\n",
       "  0.07864071428775787,\n",
       "  0.0647929459810257,\n",
       "  0.05809621885418892,\n",
       "  0.056281398981809616],\n",
       " 'class_weights_1_loss': [0.21691031754016876,\n",
       "  0.09565035998821259,\n",
       "  0.06009742617607117,\n",
       "  0.043785590678453445,\n",
       "  0.03979836404323578,\n",
       "  0.03735021501779556],\n",
       " 'class_weights_2_loss': [0.2575957775115967,\n",
       "  0.16418935358524323,\n",
       "  0.1520228236913681,\n",
       "  0.13327646255493164,\n",
       "  0.12420327216386795,\n",
       "  0.10296647995710373],\n",
       " 'class_weights_3_loss': [0.24169006943702698,\n",
       "  0.13600443303585052,\n",
       "  0.11043684929609299,\n",
       "  0.10522573441267014,\n",
       "  0.0978575050830841,\n",
       "  0.09469721466302872],\n",
       " 'class_weights_accuracy': [0.7325000166893005,\n",
       "  0.862500011920929,\n",
       "  0.9137499928474426,\n",
       "  0.9212499856948853,\n",
       "  0.9337499737739563,\n",
       "  0.9449999928474426],\n",
       " 'class_weights_1_accuracy': [0.7612500190734863,\n",
       "  0.9075000286102295,\n",
       "  0.9412500262260437,\n",
       "  0.9574999809265137,\n",
       "  0.9674999713897705,\n",
       "  0.9624999761581421],\n",
       " 'class_weights_2_accuracy': [0.6524999737739563,\n",
       "  0.7774999737739563,\n",
       "  0.8012499809265137,\n",
       "  0.8399999737739563,\n",
       "  0.8399999737739563,\n",
       "  0.8700000047683716],\n",
       " 'class_weights_3_accuracy': [0.7099999785423279,\n",
       "  0.7887499928474426,\n",
       "  0.8500000238418579,\n",
       "  0.8650000095367432,\n",
       "  0.8712499737739563,\n",
       "  0.8762500286102295],\n",
       " 'val_loss': [0.6251590847969055,\n",
       "  0.46162113547325134,\n",
       "  0.4657244384288788,\n",
       "  0.39843636751174927,\n",
       "  0.3622923791408539,\n",
       "  0.30785781145095825],\n",
       " 'val_class_weights_loss': [0.1505269557237625,\n",
       "  0.09454558044672012,\n",
       "  0.08041784167289734,\n",
       "  0.060097817331552505,\n",
       "  0.04866035282611847,\n",
       "  0.046398259699344635],\n",
       " 'val_class_weights_1_loss': [0.13554787635803223,\n",
       "  0.06550124287605286,\n",
       "  0.09156784415245056,\n",
       "  0.06080688536167145,\n",
       "  0.057105377316474915,\n",
       "  0.02648923173546791],\n",
       " 'val_class_weights_2_loss': [0.18397700786590576,\n",
       "  0.17508715391159058,\n",
       "  0.17087066173553467,\n",
       "  0.15946416556835175,\n",
       "  0.1398959755897522,\n",
       "  0.12513935565948486],\n",
       " 'val_class_weights_3_loss': [0.15510722994804382,\n",
       "  0.12648716568946838,\n",
       "  0.12286806106567383,\n",
       "  0.11806746572256088,\n",
       "  0.1166306659579277,\n",
       "  0.10983096063137054],\n",
       " 'val_class_weights_accuracy': [0.8199999928474426,\n",
       "  0.8949999809265137,\n",
       "  0.8899999856948853,\n",
       "  0.9350000023841858,\n",
       "  0.9399999976158142,\n",
       "  0.9599999785423279],\n",
       " 'val_class_weights_1_accuracy': [0.8149999976158142,\n",
       "  0.9549999833106995,\n",
       "  0.8700000047683716,\n",
       "  0.9399999976158142,\n",
       "  0.9449999928474426,\n",
       "  0.9750000238418579],\n",
       " 'val_class_weights_2_accuracy': [0.7450000047683716,\n",
       "  0.7649999856948853,\n",
       "  0.7649999856948853,\n",
       "  0.7900000214576721,\n",
       "  0.7799999713897705,\n",
       "  0.800000011920929],\n",
       " 'val_class_weights_3_accuracy': [0.7900000214576721,\n",
       "  0.8050000071525574,\n",
       "  0.8199999928474426,\n",
       "  0.8199999928474426,\n",
       "  0.824999988079071,\n",
       "  0.824999988079071]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_6_epoch_hist = H.history\n",
    "first_6_epoch_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
