{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train[:, 0:27, 0:27]\n",
    "x_test = x_test[:, 0:27, 0:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flatten = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])/255.0\n",
    "x_test_flatten = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 729) (60000,)\n",
      "(10000, 729) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_flatten.shape, y_train.shape)\n",
    "print(x_test_flatten.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5923, 729)\n",
      "(6742, 729)\n",
      "(5958, 729)\n",
      "(6131, 729)\n",
      "(5842, 729)\n",
      "(5421, 729)\n",
      "(5918, 729)\n",
      "(6265, 729)\n",
      "(5851, 729)\n",
      "(5949, 729)\n"
     ]
    }
   ],
   "source": [
    "x_train_0 = x_train_flatten[y_train == 0]\n",
    "x_train_1 = x_train_flatten[y_train == 1]\n",
    "x_train_2 = x_train_flatten[y_train == 2]\n",
    "x_train_3 = x_train_flatten[y_train == 3]\n",
    "x_train_4 = x_train_flatten[y_train == 4]\n",
    "x_train_5 = x_train_flatten[y_train == 5]\n",
    "x_train_6 = x_train_flatten[y_train == 6]\n",
    "x_train_7 = x_train_flatten[y_train == 7]\n",
    "x_train_8 = x_train_flatten[y_train == 8]\n",
    "x_train_9 = x_train_flatten[y_train == 9]\n",
    "\n",
    "x_train_list = [x_train_0, x_train_1, x_train_2, x_train_3, x_train_4, x_train_5, x_train_6, x_train_7, x_train_8, x_train_9]\n",
    "\n",
    "print(x_train_0.shape)\n",
    "print(x_train_1.shape)\n",
    "print(x_train_2.shape)\n",
    "print(x_train_3.shape)\n",
    "print(x_train_4.shape)\n",
    "print(x_train_5.shape)\n",
    "print(x_train_6.shape)\n",
    "print(x_train_7.shape)\n",
    "print(x_train_8.shape)\n",
    "print(x_train_9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(980, 729)\n",
      "(1135, 729)\n",
      "(1032, 729)\n",
      "(1010, 729)\n",
      "(982, 729)\n",
      "(892, 729)\n",
      "(958, 729)\n",
      "(1028, 729)\n",
      "(974, 729)\n",
      "(1009, 729)\n"
     ]
    }
   ],
   "source": [
    "x_test_0 = x_test_flatten[y_test == 0]\n",
    "x_test_1 = x_test_flatten[y_test == 1]\n",
    "x_test_2 = x_test_flatten[y_test == 2]\n",
    "x_test_3 = x_test_flatten[y_test == 3]\n",
    "x_test_4 = x_test_flatten[y_test == 4]\n",
    "x_test_5 = x_test_flatten[y_test == 5]\n",
    "x_test_6 = x_test_flatten[y_test == 6]\n",
    "x_test_7 = x_test_flatten[y_test == 7]\n",
    "x_test_8 = x_test_flatten[y_test == 8]\n",
    "x_test_9 = x_test_flatten[y_test == 9]\n",
    "\n",
    "x_test_list = [x_test_0, x_test_1, x_test_2, x_test_3, x_test_4, x_test_5, x_test_6, x_test_7, x_test_8, x_test_9]\n",
    "\n",
    "print(x_test_0.shape)\n",
    "print(x_test_1.shape)\n",
    "print(x_test_2.shape)\n",
    "print(x_test_3.shape)\n",
    "print(x_test_4.shape)\n",
    "print(x_test_5.shape)\n",
    "print(x_test_6.shape)\n",
    "print(x_test_7.shape)\n",
    "print(x_test_8.shape)\n",
    "print(x_test_9.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the dataset\n",
    "\n",
    "Output: X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 729), (800,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train_sample_per_class = 200\n",
    "n_class = 4\n",
    "\n",
    "X_train = x_train_list[0][:n_train_sample_per_class, :]\n",
    "Y_train = np.zeros((X_train.shape[0]*n_class,), dtype=int)\n",
    "\n",
    "for i in range(n_class-1):\n",
    "    X_train = np.concatenate((X_train, x_train_list[i+1][:n_train_sample_per_class, :]), axis=0)\n",
    "    Y_train[(i+1)*n_train_sample_per_class:(i+2)*n_train_sample_per_class] = i+1\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 729), (200,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_test_sample_per_class = int(0.25*n_train_sample_per_class)\n",
    "\n",
    "X_test = x_test_list[0][:n_test_sample_per_class, :]\n",
    "Y_test = np.zeros((X_test.shape[0]*n_class,), dtype=int)\n",
    "\n",
    "for i in range(n_class-1):\n",
    "    X_test = np.concatenate((X_test, x_test_list[i+1][:n_test_sample_per_class, :]), axis=0)\n",
    "    Y_test[(i+1)*n_test_sample_per_class:(i+2)*n_test_sample_per_class] = i+1\n",
    "\n",
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 27, 27), (200, 27, 27))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 27, 27)\n",
    "X_test = X_test.reshape(X_test.shape[0], 27, 27)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_dict = []\n",
    "for i in range(np.unique(Y_train).shape[0]):\n",
    "    temp_Y = np.zeros(Y_train.shape)\n",
    "    \n",
    "    temp_Y[Y_train == i] = 0  # positive class\n",
    "    temp_Y[Y_train != i] = 1  # negative class\n",
    "    temp_Y = to_categorical(temp_Y)\n",
    "    Y_train_dict += [('Y' + str(i), temp_Y)]\n",
    "    \n",
    "Y_train_dict = dict(Y_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_dict = []\n",
    "for i in range(np.unique(Y_test).shape[0]):\n",
    "    temp_Y = np.zeros(Y_test.shape)\n",
    "    \n",
    "    temp_Y[Y_test == i] = 0  # positive class\n",
    "    temp_Y[Y_test != i] = 1  # negative class\n",
    "    temp_Y = to_categorical(temp_Y)\n",
    "    Y_test_dict += [('Y' + str(i), temp_Y)]\n",
    "    \n",
    "Y_test_dict = dict(Y_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 2), (200, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_dict['Y1'].shape, Y_test_dict['Y0'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer, GradientDescentOptimizer\n",
    "\n",
    "qml.enable_tape()\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set a random seed\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output labels as quantum state vectors\n",
    "def density_matrix(state):\n",
    "    \"\"\"Calculates the density matrix representation of a state.\n",
    "\n",
    "    Args:\n",
    "        state (array[complex]): array representing a quantum state vector\n",
    "\n",
    "    Returns:\n",
    "        dm: (array[complex]): array representing the density matrix\n",
    "    \"\"\"\n",
    "    return state * np.conj(state).T\n",
    "\n",
    "\n",
    "label_0 = [[1], [0]]\n",
    "label_1 = [[0], [1]]\n",
    "state_labels = [label_0, label_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 2\n",
    "dev_fc = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "\n",
    "@qml.qnode(dev_fc)\n",
    "def q_fc(params, inputs):\n",
    "    \"\"\"A variational quantum circuit representing the DRC.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        inputs = [x, y]\n",
    "        x (array[float]): 1-d input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    \n",
    "    # layer iteration\n",
    "    for l in range(len(params[0])):\n",
    "        # qubit iteration\n",
    "        for q in range(n_qubits):\n",
    "            # gate iteration\n",
    "            for g in range(int(len(inputs)/3)):\n",
    "                qml.Rot(*(params[0][l][3*g:3*(g+1)] * inputs[3*g:3*(g+1)] + params[1][l][3*g:3*(g+1)]), wires=q)\n",
    "    \n",
    "    return [qml.expval(qml.Hermitian(density_matrix(state_labels[i]), wires=[i])) for i in range(n_qubits)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_conv = qml.device(\"default.qubit\", wires=9)\n",
    "\n",
    "\n",
    "@qml.qnode(dev_conv)\n",
    "def q_conv(conv_params, inputs):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier + Conv.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    # layer iteration\n",
    "    for l in range(len(conv_params[0])):\n",
    "        # RY layer\n",
    "        # height iteration\n",
    "        for i in range(3):\n",
    "            # width iteration\n",
    "            for j in range(3):\n",
    "                qml.RY((conv_params[0][l][3*i+j] * inputs[i, j] + conv_params[1][l][3*i+j]), wires=(3*i+j))\n",
    "    \n",
    "\n",
    "    return qml.expval(qml.PauliZ(0) @ qml.PauliZ(1) @ qml.PauliZ(2) @ qml.PauliZ(3) @ qml.PauliZ(4) @ qml.PauliZ(5) @ qml.PauliZ(6) @ qml.PauliZ(7) @ qml.PauliZ(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((2, 1, 9))\n",
    "q_conv(a, X_train[0, 0:3, 0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((2, 1, 9))\n",
    "q_fc(a, X_train[0, 0, 0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_weights(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(class_weights, self).__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=w_init(shape=(1, 2), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return (inputs * self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image, size = 27 x 27\n",
    "X = tf.keras.Input(shape=(27,27), name='Input_Layer')\n",
    "\n",
    "\n",
    "# Specs for Conv\n",
    "c_filter = 3\n",
    "c_strides = 2\n",
    "\n",
    "\n",
    "# First Quantum Conv Layer, trainable params = 18*L, output size = 13 x 13\n",
    "num_conv_layer_1 = 2\n",
    "q_conv_layer_1 = qml.qnn.KerasLayer(q_conv, {\"conv_params\": (2, num_conv_layer_1, 9)}, output_dim=(1), name='Quantum_Conv_Layer_1')\n",
    "size_1 = int(1+(X.shape[1]-c_filter)/c_strides)\n",
    "q_conv_layer_1_list = []\n",
    "# height iteration\n",
    "for i in range(size_1):\n",
    "    # width iteration\n",
    "    for j in range(size_1):\n",
    "        temp = q_conv_layer_1(X[:, 2*i:2*(i+1)+1, 2*j:2*(j+1)+1])\n",
    "        temp = tf.keras.layers.Reshape((1,))(temp)\n",
    "        q_conv_layer_1_list += [temp]\n",
    "concat_layer_1 = tf.keras.layers.Concatenate(axis=1)(q_conv_layer_1_list)\n",
    "reshape_layer_1 = tf.keras.layers.Reshape((size_1, size_1))(concat_layer_1)\n",
    "\n",
    "\n",
    "# Second Quantum Conv Layer, trainable params = 18*L, output size = 6 x 6\n",
    "num_conv_layer_2 = 2\n",
    "q_conv_layer_2 = qml.qnn.KerasLayer(q_conv, {\"conv_params\": (2, num_conv_layer_2, 9)}, output_dim=(1), name='Quantum_Conv_Layer_2')\n",
    "size_2 = int(1+(reshape_layer_1.shape[1]-c_filter)/c_strides)\n",
    "q_conv_layer_2_list = []\n",
    "# height iteration\n",
    "for i in range(size_2):\n",
    "    # width iteration\n",
    "    for j in range(size_2):\n",
    "        temp = q_conv_layer_2(reshape_layer_1[:, 2*i:2*(i+1)+1, 2*j:2*(j+1)+1])\n",
    "        temp = tf.keras.layers.Reshape((1,))(temp)\n",
    "        q_conv_layer_2_list += [temp]\n",
    "concat_layer_2 = tf.keras.layers.Concatenate(axis=1)(q_conv_layer_2_list)\n",
    "reshape_layer_2 = tf.keras.layers.Reshape((size_2, size_2, 1))(concat_layer_2)\n",
    "\n",
    "\n",
    "# Max Pooling Layer, output size = 9\n",
    "max_pool_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, name='Max_Pool_Layer')(reshape_layer_2)\n",
    "reshape_layer_3 = tf.keras.layers.Reshape((9,))(max_pool_layer)\n",
    "\n",
    "\n",
    "# Quantum FC Layer, trainable params = 18*L*n_class + 2, output size = 2\n",
    "num_fc_layer = 1\n",
    "q_fc_layer_0 = qml.qnn.KerasLayer(q_fc, {\"params\": (2, num_fc_layer, 9)}, output_dim=2)(reshape_layer_3)\n",
    "q_fc_layer_1 = qml.qnn.KerasLayer(q_fc, {\"params\": (2, num_fc_layer, 9)}, output_dim=2)(reshape_layer_3)\n",
    "q_fc_layer_2 = qml.qnn.KerasLayer(q_fc, {\"params\": (2, num_fc_layer, 9)}, output_dim=2)(reshape_layer_3)\n",
    "q_fc_layer_3 = qml.qnn.KerasLayer(q_fc, {\"params\": (2, num_fc_layer, 9)}, output_dim=2)(reshape_layer_3)\n",
    "\n",
    "# Alpha Layer\n",
    "alpha_layer_0 = class_weights()(q_fc_layer_0)\n",
    "alpha_layer_1 = class_weights()(q_fc_layer_1)\n",
    "alpha_layer_2 = class_weights()(q_fc_layer_2)\n",
    "alpha_layer_3 = class_weights()(q_fc_layer_3)\n",
    "\n",
    "model = tf.keras.Model(inputs=X, outputs=[alpha_layer_0, alpha_layer_1, alpha_layer_2, alpha_layer_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y_train_dict)):\n",
    "    new_key = model.layers[len(model.layers)-4+i].name\n",
    "    old_key = \"Y\" + str(i)\n",
    "    \n",
    "    Y_train_dict[new_key] = Y_train_dict.pop(old_key)\n",
    "    Y_test_dict[new_key] = Y_test_dict.pop(old_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weights': array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_1': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_2': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_3': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weights': array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_1': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_2': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_3': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       " array([[-0.05230409, -0.00997725],\n",
       "        [-0.05201906, -0.01020051],\n",
       "        [-0.05210323, -0.01013458],\n",
       "        [-0.0521341 , -0.0101104 ],\n",
       "        [-0.05224063, -0.01002696]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       " array([[ 4.0536541e-02, -9.3543684e-05],\n",
       "        [ 4.0532444e-02, -9.4595780e-05],\n",
       "        [ 4.0530793e-02, -9.5018506e-05],\n",
       "        [ 4.0538024e-02, -9.3164032e-05],\n",
       "        [ 4.0537991e-02, -9.3171926e-05]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       " array([[-0.01516563, -0.00053436],\n",
       "        [-0.0151895 , -0.00052049],\n",
       "        [-0.01518008, -0.00052597],\n",
       "        [-0.01517541, -0.00052868],\n",
       "        [-0.01519828, -0.00051539]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       " array([[-0.00916437,  0.00343957],\n",
       "        [-0.00918388,  0.00335299],\n",
       "        [-0.00917783,  0.00337984],\n",
       "        [-0.00917276,  0.00340234],\n",
       "        [-0.00918399,  0.00335249]], dtype=float32)>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[0:5, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weights': 'mse', 'class_weights_1': 'mse', 'class_weights_2': 'mse', 'class_weights_3': 'mse'}\n"
     ]
    }
   ],
   "source": [
    "losses = {\n",
    "    model.layers[len(model.layers)-4+0].name: \"mse\",\n",
    "    model.layers[len(model.layers)-4+1].name: \"mse\",\n",
    "    model.layers[len(model.layers)-4+2].name: \"mse\",\n",
    "    model.layers[len(model.layers)-4+3].name: \"mse\"\n",
    "}\n",
    "\n",
    "#lossWeights = {\"Y0\": 1.0, \"Y1\": 1.0, \"Y2\": 1.0, \"Y3\": 1.0}\n",
    "\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "model.compile(opt, loss=losses, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_val_acc = tf.keras.callbacks.ModelCheckpoint(filepath=\"./Model/QConv_4class_Branch_noent_val_acc.hdf5\",\n",
    "                monitor='val_accuracy', verbose=1, save_weights_only=True, save_best_only=True, mode='max')\n",
    "\n",
    "cp_val_loss = tf.keras.callbacks.ModelCheckpoint(filepath=\"./Model/QConv_4class_Branch_noent_val_loss.hdf5\",\n",
    "                monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 21293s 852s/step - loss: 1.3540 - class_weights_loss: 0.3537 - class_weights_1_loss: 0.3344 - class_weights_2_loss: 0.3468 - class_weights_3_loss: 0.3191 - class_weights_accuracy: 0.5591 - class_weights_1_accuracy: 0.5347 - class_weights_2_accuracy: 0.5696 - class_weights_3_accuracy: 0.6384 - val_loss: 0.7781 - val_class_weights_loss: 0.1909 - val_class_weights_1_loss: 0.1943 - val_class_weights_2_loss: 0.1963 - val_class_weights_3_loss: 0.1966 - val_class_weights_accuracy: 0.7500 - val_class_weights_1_accuracy: 0.7500 - val_class_weights_2_accuracy: 0.7500 - val_class_weights_3_accuracy: 0.7500\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.77812, saving model to ./Model/QConv_4class_Branch_noent_val_loss.hdf5\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 21047s 843s/step - loss: 0.8108 - class_weights_loss: 0.1877 - class_weights_1_loss: 0.2190 - class_weights_2_loss: 0.2120 - class_weights_3_loss: 0.1920 - class_weights_accuracy: 0.7584 - class_weights_1_accuracy: 0.7473 - class_weights_2_accuracy: 0.6811 - class_weights_3_accuracy: 0.7622 - val_loss: 0.7409 - val_class_weights_loss: 0.1797 - val_class_weights_1_loss: 0.1851 - val_class_weights_2_loss: 0.1901 - val_class_weights_3_loss: 0.1860 - val_class_weights_accuracy: 0.7500 - val_class_weights_1_accuracy: 0.7500 - val_class_weights_2_accuracy: 0.7500 - val_class_weights_3_accuracy: 0.7500\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss improved from 0.77812 to 0.74088, saving model to ./Model/QConv_4class_Branch_noent_val_loss.hdf5\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 21576s 864s/step - loss: 0.7040 - class_weights_loss: 0.1638 - class_weights_1_loss: 0.1588 - class_weights_2_loss: 0.1931 - class_weights_3_loss: 0.1882 - class_weights_accuracy: 0.7600 - class_weights_1_accuracy: 0.7808 - class_weights_2_accuracy: 0.7410 - class_weights_3_accuracy: 0.7340 - val_loss: 0.5436 - val_class_weights_loss: 0.1130 - val_class_weights_1_loss: 0.0797 - val_class_weights_2_loss: 0.1725 - val_class_weights_3_loss: 0.1785 - val_class_weights_accuracy: 0.8250 - val_class_weights_1_accuracy: 0.8750 - val_class_weights_2_accuracy: 0.7500 - val_class_weights_3_accuracy: 0.7500\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss improved from 0.74088 to 0.54362, saving model to ./Model/QConv_4class_Branch_noent_val_loss.hdf5\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 21941s 879s/step - loss: 0.5652 - class_weights_loss: 0.1173 - class_weights_1_loss: 0.0872 - class_weights_2_loss: 0.1867 - class_weights_3_loss: 0.1740 - class_weights_accuracy: 0.8118 - class_weights_1_accuracy: 0.9002 - class_weights_2_accuracy: 0.7385 - class_weights_3_accuracy: 0.7397 - val_loss: 0.5135 - val_class_weights_loss: 0.1085 - val_class_weights_1_loss: 0.0929 - val_class_weights_2_loss: 0.1536 - val_class_weights_3_loss: 0.1586 - val_class_weights_accuracy: 0.8900 - val_class_weights_1_accuracy: 0.8450 - val_class_weights_2_accuracy: 0.7550 - val_class_weights_3_accuracy: 0.7550\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss improved from 0.54362 to 0.51352, saving model to ./Model/QConv_4class_Branch_noent_val_loss.hdf5\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 21665s 867s/step - loss: 0.5044 - class_weights_loss: 0.0949 - class_weights_1_loss: 0.0792 - class_weights_2_loss: 0.1608 - class_weights_3_loss: 0.1695 - class_weights_accuracy: 0.8690 - class_weights_1_accuracy: 0.9072 - class_weights_2_accuracy: 0.7864 - class_weights_3_accuracy: 0.7368 - val_loss: 0.4638 - val_class_weights_loss: 0.0563 - val_class_weights_1_loss: 0.0773 - val_class_weights_2_loss: 0.1580 - val_class_weights_3_loss: 0.1723 - val_class_weights_accuracy: 0.9500 - val_class_weights_1_accuracy: 0.9350 - val_class_weights_2_accuracy: 0.7700 - val_class_weights_3_accuracy: 0.7500\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss improved from 0.51352 to 0.46384, saving model to ./Model/QConv_4class_Branch_noent_val_loss.hdf5\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 21075s 844s/step - loss: 0.4722 - class_weights_loss: 0.0731 - class_weights_1_loss: 0.0706 - class_weights_2_loss: 0.1671 - class_weights_3_loss: 0.1614 - class_weights_accuracy: 0.9079 - class_weights_1_accuracy: 0.9265 - class_weights_2_accuracy: 0.7612 - class_weights_3_accuracy: 0.7552 - val_loss: 0.4182 - val_class_weights_loss: 0.0701 - val_class_weights_1_loss: 0.0547 - val_class_weights_2_loss: 0.1583 - val_class_weights_3_loss: 0.1351 - val_class_weights_accuracy: 0.9150 - val_class_weights_1_accuracy: 0.9450 - val_class_weights_2_accuracy: 0.7350 - val_class_weights_3_accuracy: 0.8100\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_loss improved from 0.46384 to 0.41819, saving model to ./Model/QConv_4class_Branch_noent_val_loss.hdf5\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 21281s 852s/step - loss: 0.4237 - class_weights_loss: 0.0756 - class_weights_1_loss: 0.0637 - class_weights_2_loss: 0.1546 - class_weights_3_loss: 0.1299 - class_weights_accuracy: 0.9074 - class_weights_1_accuracy: 0.9287 - class_weights_2_accuracy: 0.7786 - class_weights_3_accuracy: 0.8109 - val_loss: 0.4820 - val_class_weights_loss: 0.0877 - val_class_weights_1_loss: 0.0758 - val_class_weights_2_loss: 0.1745 - val_class_weights_3_loss: 0.1440 - val_class_weights_accuracy: 0.9200 - val_class_weights_1_accuracy: 0.9300 - val_class_weights_2_accuracy: 0.7700 - val_class_weights_3_accuracy: 0.7800\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_loss did not improve from 0.41819\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 21495s 861s/step - loss: 0.4151 - class_weights_loss: 0.0677 - class_weights_1_loss: 0.0763 - class_weights_2_loss: 0.1384 - class_weights_3_loss: 0.1326 - class_weights_accuracy: 0.9266 - class_weights_1_accuracy: 0.9057 - class_weights_2_accuracy: 0.8018 - class_weights_3_accuracy: 0.7879 - val_loss: 0.3949 - val_class_weights_loss: 0.0551 - val_class_weights_1_loss: 0.0551 - val_class_weights_2_loss: 0.1438 - val_class_weights_3_loss: 0.1410 - val_class_weights_accuracy: 0.9400 - val_class_weights_1_accuracy: 0.9600 - val_class_weights_2_accuracy: 0.7650 - val_class_weights_3_accuracy: 0.7750\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_loss improved from 0.41819 to 0.39493, saving model to ./Model/QConv_4class_Branch_noent_val_loss.hdf5\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 21428s 858s/step - loss: 0.4104 - class_weights_loss: 0.0624 - class_weights_1_loss: 0.0575 - class_weights_2_loss: 0.1542 - class_weights_3_loss: 0.1363 - class_weights_accuracy: 0.9270 - class_weights_1_accuracy: 0.9514 - class_weights_2_accuracy: 0.7713 - class_weights_3_accuracy: 0.8027 - val_loss: 0.3879 - val_class_weights_loss: 0.0674 - val_class_weights_1_loss: 0.0544 - val_class_weights_2_loss: 0.1340 - val_class_weights_3_loss: 0.1322 - val_class_weights_accuracy: 0.9200 - val_class_weights_1_accuracy: 0.9500 - val_class_weights_2_accuracy: 0.8100 - val_class_weights_3_accuracy: 0.8000\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00009: val_loss improved from 0.39493 to 0.38791, saving model to ./Model/QConv_4class_Branch_noent_val_loss.hdf5\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 20684s 828s/step - loss: 0.4062 - class_weights_loss: 0.0678 - class_weights_1_loss: 0.0613 - class_weights_2_loss: 0.1486 - class_weights_3_loss: 0.1286 - class_weights_accuracy: 0.9267 - class_weights_1_accuracy: 0.9419 - class_weights_2_accuracy: 0.8043 - class_weights_3_accuracy: 0.8021 - val_loss: 0.3989 - val_class_weights_loss: 0.0483 - val_class_weights_1_loss: 0.0526 - val_class_weights_2_loss: 0.1569 - val_class_weights_3_loss: 0.1411 - val_class_weights_accuracy: 0.9450 - val_class_weights_1_accuracy: 0.9600 - val_class_weights_2_accuracy: 0.7700 - val_class_weights_3_accuracy: 0.7850\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss did not improve from 0.38791\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(X_train, Y_train_dict, epochs=10, batch_size=32,\n",
    "              validation_data=(X_test, Y_test_dict), verbose=1, initial_epoch=0,\n",
    "              callbacks=[cp_val_acc, cp_val_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.0506396293640137,\n",
       "  0.7910139560699463,\n",
       "  0.6599786877632141,\n",
       "  0.5440919995307922,\n",
       "  0.4907117784023285,\n",
       "  0.45721301436424255,\n",
       "  0.41313889622688293,\n",
       "  0.4362773895263672,\n",
       "  0.426174134016037,\n",
       "  0.41872572898864746],\n",
       " 'class_weights_loss': [0.27082207798957825,\n",
       "  0.18940392136573792,\n",
       "  0.14577800035476685,\n",
       "  0.11382559686899185,\n",
       "  0.08704619109630585,\n",
       "  0.07399170845746994,\n",
       "  0.07011676579713821,\n",
       "  0.07591637969017029,\n",
       "  0.06972875446081161,\n",
       "  0.06298992037773132],\n",
       " 'class_weights_1_loss': [0.2583957612514496,\n",
       "  0.2089381217956543,\n",
       "  0.14342397451400757,\n",
       "  0.07761059701442719,\n",
       "  0.0758456140756607,\n",
       "  0.06776565313339233,\n",
       "  0.060261402279138565,\n",
       "  0.07645382732152939,\n",
       "  0.06485393643379211,\n",
       "  0.06485885381698608],\n",
       " 'class_weights_2_loss': [0.2706368565559387,\n",
       "  0.20032350718975067,\n",
       "  0.1897687166929245,\n",
       "  0.17996013164520264,\n",
       "  0.1668419986963272,\n",
       "  0.16219498217105865,\n",
       "  0.15446029603481293,\n",
       "  0.15266697108745575,\n",
       "  0.15023504197597504,\n",
       "  0.154896080493927],\n",
       " 'class_weights_3_loss': [0.25078481435775757,\n",
       "  0.19234836101531982,\n",
       "  0.18100792169570923,\n",
       "  0.17269569635391235,\n",
       "  0.16097797453403473,\n",
       "  0.15326064825057983,\n",
       "  0.12830045819282532,\n",
       "  0.13124024868011475,\n",
       "  0.14135634899139404,\n",
       "  0.13598085939884186],\n",
       " 'class_weights_accuracy': [0.6337500214576721,\n",
       "  0.75,\n",
       "  0.7825000286102295,\n",
       "  0.8262500166893005,\n",
       "  0.8824999928474426,\n",
       "  0.9087499976158142,\n",
       "  0.9225000143051147,\n",
       "  0.90625,\n",
       "  0.9212499856948853,\n",
       "  0.9350000023841858],\n",
       " 'class_weights_1_accuracy': [0.6700000166893005,\n",
       "  0.75,\n",
       "  0.7950000166893005,\n",
       "  0.9112499952316284,\n",
       "  0.9137499928474426,\n",
       "  0.9275000095367432,\n",
       "  0.9350000023841858,\n",
       "  0.9024999737739563,\n",
       "  0.9337499737739563,\n",
       "  0.9350000023841858],\n",
       " 'class_weights_2_accuracy': [0.6449999809265137,\n",
       "  0.7275000214576721,\n",
       "  0.7400000095367432,\n",
       "  0.7437499761581421,\n",
       "  0.7762500047683716,\n",
       "  0.762499988079071,\n",
       "  0.7724999785423279,\n",
       "  0.7724999785423279,\n",
       "  0.7825000286102295,\n",
       "  0.7925000190734863],\n",
       " 'class_weights_3_accuracy': [0.6924999952316284,\n",
       "  0.75,\n",
       "  0.7462499737739563,\n",
       "  0.7462499737739563,\n",
       "  0.7587500214576721,\n",
       "  0.7612500190734863,\n",
       "  0.8075000047683716,\n",
       "  0.800000011920929,\n",
       "  0.800000011920929,\n",
       "  0.793749988079071],\n",
       " 'val_loss': [0.7781184911727905,\n",
       "  0.7408773899078369,\n",
       "  0.5436155796051025,\n",
       "  0.5135173201560974,\n",
       "  0.46383655071258545,\n",
       "  0.41819262504577637,\n",
       "  0.4819645583629608,\n",
       "  0.3949328362941742,\n",
       "  0.38790565729141235,\n",
       "  0.39888808131217957],\n",
       " 'val_class_weights_loss': [0.19092409312725067,\n",
       "  0.17972606420516968,\n",
       "  0.11302470415830612,\n",
       "  0.10850367695093155,\n",
       "  0.05625813826918602,\n",
       "  0.07014555484056473,\n",
       "  0.08774742484092712,\n",
       "  0.055050767958164215,\n",
       "  0.06736171990633011,\n",
       "  0.04826206713914871],\n",
       " 'val_class_weights_1_loss': [0.1942921280860901,\n",
       "  0.18505042791366577,\n",
       "  0.07966086268424988,\n",
       "  0.09285178035497665,\n",
       "  0.07729771733283997,\n",
       "  0.0546799935400486,\n",
       "  0.07578328251838684,\n",
       "  0.055050358176231384,\n",
       "  0.05441047623753548,\n",
       "  0.052594128996133804],\n",
       " 'val_class_weights_2_loss': [0.19634316861629486,\n",
       "  0.19009868800640106,\n",
       "  0.17247897386550903,\n",
       "  0.1536051630973816,\n",
       "  0.1579829752445221,\n",
       "  0.15830767154693604,\n",
       "  0.17446132004261017,\n",
       "  0.14384779334068298,\n",
       "  0.1339721530675888,\n",
       "  0.15689456462860107],\n",
       " 'val_class_weights_3_loss': [0.19655902683734894,\n",
       "  0.1860022395849228,\n",
       "  0.1784510612487793,\n",
       "  0.1585567146539688,\n",
       "  0.17229774594306946,\n",
       "  0.1350594162940979,\n",
       "  0.1439725160598755,\n",
       "  0.14098387956619263,\n",
       "  0.13216128945350647,\n",
       "  0.14113733172416687],\n",
       " 'val_class_weights_accuracy': [0.75,\n",
       "  0.75,\n",
       "  0.824999988079071,\n",
       "  0.8899999856948853,\n",
       "  0.949999988079071,\n",
       "  0.9150000214576721,\n",
       "  0.9200000166893005,\n",
       "  0.9399999976158142,\n",
       "  0.9200000166893005,\n",
       "  0.9449999928474426],\n",
       " 'val_class_weights_1_accuracy': [0.75,\n",
       "  0.75,\n",
       "  0.875,\n",
       "  0.8450000286102295,\n",
       "  0.9350000023841858,\n",
       "  0.9449999928474426,\n",
       "  0.9300000071525574,\n",
       "  0.9599999785423279,\n",
       "  0.949999988079071,\n",
       "  0.9599999785423279],\n",
       " 'val_class_weights_2_accuracy': [0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.7549999952316284,\n",
       "  0.7699999809265137,\n",
       "  0.7350000143051147,\n",
       "  0.7699999809265137,\n",
       "  0.7649999856948853,\n",
       "  0.8100000023841858,\n",
       "  0.7699999809265137],\n",
       " 'val_class_weights_3_accuracy': [0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.7549999952316284,\n",
       "  0.75,\n",
       "  0.8100000023841858,\n",
       "  0.7799999713897705,\n",
       "  0.7749999761581421,\n",
       "  0.800000011920929,\n",
       "  0.7850000262260437]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'model/Quantum_Conv_Layer_1/conv_params:0' shape=(2, 2, 9) dtype=float32, numpy=\n",
       " array([[[-2.879157  , -0.06113851, -1.250127  ,  0.20932803,\n",
       "           0.21565051,  1.527982  , -0.11106659, -0.85923535,\n",
       "          -0.72602797],\n",
       "         [-2.8942282 , -0.03071501, -0.42789447, -0.13308612,\n",
       "          -0.44581786,  0.7169748 , -0.17850608, -0.7448239 ,\n",
       "          -0.09231876]],\n",
       " \n",
       "        [[-2.1716294 , -0.59827197,  0.01797469,  0.12302922,\n",
       "           0.13206989,  0.03544942,  0.23999068, -1.4335662 ,\n",
       "          -0.30536836],\n",
       "         [-1.5368237 , -0.18688755, -0.22701311, -0.37563765,\n",
       "           0.20884033,  0.21695429, -0.1548334 , -1.8039789 ,\n",
       "          -0.07404009]]], dtype=float32)>,\n",
       " <tf.Variable 'model/Quantum_Conv_Layer_2/conv_params:0' shape=(2, 2, 9) dtype=float32, numpy=\n",
       " array([[[ 0.08249889, -1.1355494 ,  0.44110522, -0.49258783,\n",
       "           0.8296524 , -2.7006702 , -0.07375239, -0.60858023,\n",
       "           0.60580844],\n",
       "         [ 0.07066029, -0.36096725,  0.33978   , -1.3050234 ,\n",
       "           1.3748775 , -2.6253285 ,  0.06848841,  0.09683187,\n",
       "           0.83297837]],\n",
       " \n",
       "        [[ 0.02925751,  0.3862955 ,  0.14755896,  0.19861042,\n",
       "          -0.2899392 ,  0.25150838,  0.13935901,  0.384241  ,\n",
       "           0.43940502],\n",
       "         [-0.09283531,  0.32746372, -0.38341588, -0.24564001,\n",
       "           0.2385557 , -0.2755102 ,  0.08972058, -0.31192714,\n",
       "          -0.19811732]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[-0.3940266 , -0.57118386,  0.9162974 ,  3.634999  ,\n",
       "           2.6704707 ,  3.6220675 ,  0.17357439,  0.5440204 ,\n",
       "          -0.16413271]],\n",
       " \n",
       "        [[ 0.10660796,  0.83348244,  0.1784173 ,  0.18844227,\n",
       "           0.8292179 ,  0.7499824 ,  0.39429134,  0.08543225,\n",
       "           0.41910002]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_1/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[-0.1558212 , -2.3120546 ,  0.32703567,  3.0440211 ,\n",
       "           0.28175494,  0.24931383,  1.602881  , -1.5607389 ,\n",
       "           0.25357637]],\n",
       " \n",
       "        [[ 0.42489275, -0.96802175, -1.2910931 , -1.108924  ,\n",
       "          -1.0455397 ,  0.7388851 ,  0.8929635 ,  0.35100183,\n",
       "          -0.26780948]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_2/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[-0.35058895, -0.9181965 , -0.5718978 , -1.397891  ,\n",
       "          -2.3868663 ,  1.1868953 ,  0.7384271 , -1.4058212 ,\n",
       "           0.50455487]],\n",
       " \n",
       "        [[-0.51556647, -0.67395234,  0.09227207,  0.97955173,\n",
       "          -1.378524  ,  1.0746034 ,  1.3095661 ,  1.1721439 ,\n",
       "          -0.06640413]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_3/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[-0.26901227,  0.23922576,  0.10831148, -3.465561  ,\n",
       "           2.0822823 ,  0.6779116 ,  0.98795635,  1.3871717 ,\n",
       "           0.21118878]],\n",
       " \n",
       "        [[ 0.48024678,  0.7152524 ,  0.01049931,  0.24269372,\n",
       "           1.0593714 ,  0.01603149, -0.12155312,  0.8677479 ,\n",
       "          -0.06092391]]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1.0187517, 1.0581502]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1.0109764, 1.0454198]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[0.7876619, 1.1645983]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[0.87596864, 1.0285345 ]], dtype=float32)>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2222222222222223"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1L QConv1, 1L QConv2, 1L QFC, no entangler at all\n",
    "# 1 epoch = ... jam\n",
    "8000/(60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.322222222222222"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "26360/(60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'model/Quantum_Conv_Layer_1/conv_params:0' shape=(2, 2, 9) dtype=float32, numpy=\n",
       " array([[[ 0.30478922,  0.24122563,  1.2013984 ,  0.8962295 ,\n",
       "           2.155613  ,  1.808066  , -0.6777786 , -1.3539367 ,\n",
       "           0.46882528],\n",
       "         [ 0.10804682,  0.4899469 , -1.4487113 ,  0.18007451,\n",
       "           0.21117014, -0.07102177,  0.22456087,  0.19595939,\n",
       "           0.620559  ]],\n",
       " \n",
       "        [[ 0.08490325, -0.46300295,  0.88712513,  0.21560192,\n",
       "           0.68917143, -1.3093163 ,  1.0160891 , -0.17013887,\n",
       "           0.09957722],\n",
       "         [ 0.08793638, -0.0810757 , -0.3338206 ,  0.5029927 ,\n",
       "           0.46003294,  0.47570366, -0.18548904, -0.2648427 ,\n",
       "          -0.0655445 ]]], dtype=float32)>,\n",
       " <tf.Variable 'model/Quantum_Conv_Layer_2/conv_params:0' shape=(2, 2, 9) dtype=float32, numpy=\n",
       " array([[[ 2.7642950e-01,  2.3297124e+00, -7.7425838e-01,  4.8847955e-01,\n",
       "           4.3419965e-02, -3.3615255e-01, -1.0063299e+00,  2.2314610e+00,\n",
       "           9.1715485e-01],\n",
       "         [-4.1352111e-01,  3.0436099e-02, -1.2301649e+00,  1.7263293e-03,\n",
       "          -1.5698449e-01,  4.4744748e-01,  1.2136365e+00,  2.7647603e-01,\n",
       "           1.0283145e+00]],\n",
       " \n",
       "        [[-3.3875754e-01,  1.0402726e+00, -4.2845064e-01,  7.4869722e-02,\n",
       "           3.8802050e-02,  3.3155876e-01, -7.6660907e-01,  3.3909407e-01,\n",
       "           3.5294789e-01],\n",
       "         [ 6.6214994e-02, -1.3985926e-01,  9.4863945e-01, -1.1182010e-01,\n",
       "           2.7276468e-01,  3.9622694e-01,  3.1741151e-01, -2.2376621e-01,\n",
       "           3.0038670e-01]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[-0.05643808, -0.3834348 ,  1.3783973 ,  1.8028375 ,\n",
       "           2.4020152 ,  3.265065  ,  0.04925077,  0.18717681,\n",
       "          -0.15576944]],\n",
       " \n",
       "        [[ 0.0552775 ,  0.83352816,  0.51252973,  0.67993635,\n",
       "           1.538679  ,  0.5075311 ,  1.462727  ,  0.28211135,\n",
       "          -0.18711801]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_1/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[ 0.5008777 , -1.3495312 , -0.5218247 ,  1.51395   ,\n",
       "           0.70898056,  1.331641  ,  0.75333315,  1.1442982 ,\n",
       "          -0.283115  ]],\n",
       " \n",
       "        [[ 0.23336929,  1.3037012 , -0.16543525, -0.8135664 ,\n",
       "           0.5298867 , -0.08688857, -0.40758485,  1.3480728 ,\n",
       "          -0.06701605]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_2/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[ 0.20852552, -0.92169833,  0.20204262, -1.4812163 ,\n",
       "           0.00889985, -1.5283754 , -0.8842213 , -2.125618  ,\n",
       "          -0.2756645 ]],\n",
       " \n",
       "        [[ 0.19089271, -1.2583857 , -0.05586167, -0.65264225,\n",
       "           0.72431535, -0.6168651 , -0.59993476, -2.472832  ,\n",
       "           0.120191  ]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_3/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[-0.30617303,  0.06194295, -0.42034343, -1.888615  ,\n",
       "          -2.2937555 ,  0.68672144,  1.2960382 , -1.1311744 ,\n",
       "          -0.19152352]],\n",
       " \n",
       "        [[-0.12496919, -0.75718635, -0.21456823, -0.07930091,\n",
       "          -0.44249678, -0.28310478,  0.76265246, -1.462515  ,\n",
       "           0.08680444]]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[0.9889597, 1.064973 ]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1.0520185, 1.0743465]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1.0430095, 1.0347432]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1.0084324, 1.0561559]], dtype=float32)>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_6_epoch_weights = model.weights\n",
    "first_6_epoch_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.9413223266601562,\n",
       "  0.5048812627792358,\n",
       "  0.4011978209018707,\n",
       "  0.347080796957016,\n",
       "  0.31995534896850586,\n",
       "  0.29129528999328613],\n",
       " 'class_weights_loss': [0.2251260131597519,\n",
       "  0.1090371310710907,\n",
       "  0.07864071428775787,\n",
       "  0.0647929459810257,\n",
       "  0.05809621885418892,\n",
       "  0.056281398981809616],\n",
       " 'class_weights_1_loss': [0.21691031754016876,\n",
       "  0.09565035998821259,\n",
       "  0.06009742617607117,\n",
       "  0.043785590678453445,\n",
       "  0.03979836404323578,\n",
       "  0.03735021501779556],\n",
       " 'class_weights_2_loss': [0.2575957775115967,\n",
       "  0.16418935358524323,\n",
       "  0.1520228236913681,\n",
       "  0.13327646255493164,\n",
       "  0.12420327216386795,\n",
       "  0.10296647995710373],\n",
       " 'class_weights_3_loss': [0.24169006943702698,\n",
       "  0.13600443303585052,\n",
       "  0.11043684929609299,\n",
       "  0.10522573441267014,\n",
       "  0.0978575050830841,\n",
       "  0.09469721466302872],\n",
       " 'class_weights_accuracy': [0.7325000166893005,\n",
       "  0.862500011920929,\n",
       "  0.9137499928474426,\n",
       "  0.9212499856948853,\n",
       "  0.9337499737739563,\n",
       "  0.9449999928474426],\n",
       " 'class_weights_1_accuracy': [0.7612500190734863,\n",
       "  0.9075000286102295,\n",
       "  0.9412500262260437,\n",
       "  0.9574999809265137,\n",
       "  0.9674999713897705,\n",
       "  0.9624999761581421],\n",
       " 'class_weights_2_accuracy': [0.6524999737739563,\n",
       "  0.7774999737739563,\n",
       "  0.8012499809265137,\n",
       "  0.8399999737739563,\n",
       "  0.8399999737739563,\n",
       "  0.8700000047683716],\n",
       " 'class_weights_3_accuracy': [0.7099999785423279,\n",
       "  0.7887499928474426,\n",
       "  0.8500000238418579,\n",
       "  0.8650000095367432,\n",
       "  0.8712499737739563,\n",
       "  0.8762500286102295],\n",
       " 'val_loss': [0.6251590847969055,\n",
       "  0.46162113547325134,\n",
       "  0.4657244384288788,\n",
       "  0.39843636751174927,\n",
       "  0.3622923791408539,\n",
       "  0.30785781145095825],\n",
       " 'val_class_weights_loss': [0.1505269557237625,\n",
       "  0.09454558044672012,\n",
       "  0.08041784167289734,\n",
       "  0.060097817331552505,\n",
       "  0.04866035282611847,\n",
       "  0.046398259699344635],\n",
       " 'val_class_weights_1_loss': [0.13554787635803223,\n",
       "  0.06550124287605286,\n",
       "  0.09156784415245056,\n",
       "  0.06080688536167145,\n",
       "  0.057105377316474915,\n",
       "  0.02648923173546791],\n",
       " 'val_class_weights_2_loss': [0.18397700786590576,\n",
       "  0.17508715391159058,\n",
       "  0.17087066173553467,\n",
       "  0.15946416556835175,\n",
       "  0.1398959755897522,\n",
       "  0.12513935565948486],\n",
       " 'val_class_weights_3_loss': [0.15510722994804382,\n",
       "  0.12648716568946838,\n",
       "  0.12286806106567383,\n",
       "  0.11806746572256088,\n",
       "  0.1166306659579277,\n",
       "  0.10983096063137054],\n",
       " 'val_class_weights_accuracy': [0.8199999928474426,\n",
       "  0.8949999809265137,\n",
       "  0.8899999856948853,\n",
       "  0.9350000023841858,\n",
       "  0.9399999976158142,\n",
       "  0.9599999785423279],\n",
       " 'val_class_weights_1_accuracy': [0.8149999976158142,\n",
       "  0.9549999833106995,\n",
       "  0.8700000047683716,\n",
       "  0.9399999976158142,\n",
       "  0.9449999928474426,\n",
       "  0.9750000238418579],\n",
       " 'val_class_weights_2_accuracy': [0.7450000047683716,\n",
       "  0.7649999856948853,\n",
       "  0.7649999856948853,\n",
       "  0.7900000214576721,\n",
       "  0.7799999713897705,\n",
       "  0.800000011920929],\n",
       " 'val_class_weights_3_accuracy': [0.7900000214576721,\n",
       "  0.8050000071525574,\n",
       "  0.8199999928474426,\n",
       "  0.8199999928474426,\n",
       "  0.824999988079071,\n",
       "  0.824999988079071]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_6_epoch_hist = H.history\n",
    "first_6_epoch_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
