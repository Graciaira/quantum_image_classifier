{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train[:, 0:27, 0:27]\n",
    "x_test = x_test[:, 0:27, 0:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flatten = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])/255.0\n",
    "x_test_flatten = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 729) (60000,)\n",
      "(10000, 729) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_flatten.shape, y_train.shape)\n",
    "print(x_test_flatten.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5923, 729)\n",
      "(6742, 729)\n",
      "(5958, 729)\n",
      "(6131, 729)\n",
      "(5842, 729)\n",
      "(5421, 729)\n",
      "(5918, 729)\n",
      "(6265, 729)\n",
      "(5851, 729)\n",
      "(5949, 729)\n"
     ]
    }
   ],
   "source": [
    "x_train_0 = x_train_flatten[y_train == 0]\n",
    "x_train_1 = x_train_flatten[y_train == 1]\n",
    "x_train_2 = x_train_flatten[y_train == 2]\n",
    "x_train_3 = x_train_flatten[y_train == 3]\n",
    "x_train_4 = x_train_flatten[y_train == 4]\n",
    "x_train_5 = x_train_flatten[y_train == 5]\n",
    "x_train_6 = x_train_flatten[y_train == 6]\n",
    "x_train_7 = x_train_flatten[y_train == 7]\n",
    "x_train_8 = x_train_flatten[y_train == 8]\n",
    "x_train_9 = x_train_flatten[y_train == 9]\n",
    "\n",
    "x_train_list = [x_train_0, x_train_1, x_train_2, x_train_3, x_train_4, x_train_5, x_train_6, x_train_7, x_train_8, x_train_9]\n",
    "\n",
    "print(x_train_0.shape)\n",
    "print(x_train_1.shape)\n",
    "print(x_train_2.shape)\n",
    "print(x_train_3.shape)\n",
    "print(x_train_4.shape)\n",
    "print(x_train_5.shape)\n",
    "print(x_train_6.shape)\n",
    "print(x_train_7.shape)\n",
    "print(x_train_8.shape)\n",
    "print(x_train_9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(980, 729)\n",
      "(1135, 729)\n",
      "(1032, 729)\n",
      "(1010, 729)\n",
      "(982, 729)\n",
      "(892, 729)\n",
      "(958, 729)\n",
      "(1028, 729)\n",
      "(974, 729)\n",
      "(1009, 729)\n"
     ]
    }
   ],
   "source": [
    "x_test_0 = x_test_flatten[y_test == 0]\n",
    "x_test_1 = x_test_flatten[y_test == 1]\n",
    "x_test_2 = x_test_flatten[y_test == 2]\n",
    "x_test_3 = x_test_flatten[y_test == 3]\n",
    "x_test_4 = x_test_flatten[y_test == 4]\n",
    "x_test_5 = x_test_flatten[y_test == 5]\n",
    "x_test_6 = x_test_flatten[y_test == 6]\n",
    "x_test_7 = x_test_flatten[y_test == 7]\n",
    "x_test_8 = x_test_flatten[y_test == 8]\n",
    "x_test_9 = x_test_flatten[y_test == 9]\n",
    "\n",
    "x_test_list = [x_test_0, x_test_1, x_test_2, x_test_3, x_test_4, x_test_5, x_test_6, x_test_7, x_test_8, x_test_9]\n",
    "\n",
    "print(x_test_0.shape)\n",
    "print(x_test_1.shape)\n",
    "print(x_test_2.shape)\n",
    "print(x_test_3.shape)\n",
    "print(x_test_4.shape)\n",
    "print(x_test_5.shape)\n",
    "print(x_test_6.shape)\n",
    "print(x_test_7.shape)\n",
    "print(x_test_8.shape)\n",
    "print(x_test_9.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the dataset\n",
    "\n",
    "Output: X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 729), (800,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train_sample_per_class = 200\n",
    "n_class = 4\n",
    "\n",
    "X_train = x_train_list[0][:n_train_sample_per_class, :]\n",
    "Y_train = np.zeros((X_train.shape[0]*n_class,), dtype=int)\n",
    "\n",
    "for i in range(n_class-1):\n",
    "    X_train = np.concatenate((X_train, x_train_list[i+1][:n_train_sample_per_class, :]), axis=0)\n",
    "    Y_train[(i+1)*n_train_sample_per_class:(i+2)*n_train_sample_per_class] = i+1\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 729), (200,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_test_sample_per_class = int(0.25*n_train_sample_per_class)\n",
    "\n",
    "X_test = x_test_list[0][:n_test_sample_per_class, :]\n",
    "Y_test = np.zeros((X_test.shape[0]*n_class,), dtype=int)\n",
    "\n",
    "for i in range(n_class-1):\n",
    "    X_test = np.concatenate((X_test, x_test_list[i+1][:n_test_sample_per_class, :]), axis=0)\n",
    "    Y_test[(i+1)*n_test_sample_per_class:(i+2)*n_test_sample_per_class] = i+1\n",
    "\n",
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 27, 27), (200, 27, 27))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 27, 27)\n",
    "X_test = X_test.reshape(X_test.shape[0], 27, 27)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_dict = []\n",
    "for i in range(np.unique(Y_train).shape[0]):\n",
    "    temp_Y = np.zeros(Y_train.shape)\n",
    "    \n",
    "    temp_Y[Y_train == i] = 0  # positive class\n",
    "    temp_Y[Y_train != i] = 1  # negative class\n",
    "    temp_Y = to_categorical(temp_Y)\n",
    "    Y_train_dict += [('Y' + str(i), temp_Y)]\n",
    "    \n",
    "Y_train_dict = dict(Y_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_dict = []\n",
    "for i in range(np.unique(Y_test).shape[0]):\n",
    "    temp_Y = np.zeros(Y_test.shape)\n",
    "    \n",
    "    temp_Y[Y_test == i] = 0  # positive class\n",
    "    temp_Y[Y_test != i] = 1  # negative class\n",
    "    temp_Y = to_categorical(temp_Y)\n",
    "    Y_test_dict += [('Y' + str(i), temp_Y)]\n",
    "    \n",
    "Y_test_dict = dict(Y_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 2), (200, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_dict['Y1'].shape, Y_test_dict['Y0'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer, GradientDescentOptimizer\n",
    "\n",
    "qml.enable_tape()\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set a random seed\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output labels as quantum state vectors\n",
    "def density_matrix(state):\n",
    "    \"\"\"Calculates the density matrix representation of a state.\n",
    "\n",
    "    Args:\n",
    "        state (array[complex]): array representing a quantum state vector\n",
    "\n",
    "    Returns:\n",
    "        dm: (array[complex]): array representing the density matrix\n",
    "    \"\"\"\n",
    "    return state * np.conj(state).T\n",
    "\n",
    "\n",
    "label_0 = [[1], [0]]\n",
    "label_1 = [[0], [1]]\n",
    "state_labels = [label_0, label_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 2\n",
    "dev_fc = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "\n",
    "@qml.qnode(dev_fc)\n",
    "def q_fc(params, inputs):\n",
    "    \"\"\"A variational quantum circuit representing the DRC.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        inputs = [x, y]\n",
    "        x (array[float]): 1-d input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    \n",
    "    # layer iteration\n",
    "    for l in range(len(params[0])):\n",
    "        # qubit iteration\n",
    "        for q in range(n_qubits):\n",
    "            # gate iteration\n",
    "            for g in range(int(len(inputs)/3)):\n",
    "                qml.Rot(*(params[0][l][3*g:3*(g+1)] * inputs[3*g:3*(g+1)] + params[1][l][3*g:3*(g+1)]), wires=q)\n",
    "    \n",
    "    return [qml.expval(qml.Hermitian(density_matrix(state_labels[i]), wires=[i])) for i in range(n_qubits)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_conv = qml.device(\"default.qubit\", wires=9)\n",
    "\n",
    "\n",
    "@qml.qnode(dev_conv)\n",
    "def q_conv(conv_params, inputs):\n",
    "    \"\"\"A variational quantum circuit representing the Universal classifier + Conv.\n",
    "\n",
    "    Args:\n",
    "        params (array[float]): array of parameters\n",
    "        x (array[float]): 2-d input vector\n",
    "        y (array[float]): single output state density matrix\n",
    "\n",
    "    Returns:\n",
    "        float: fidelity between output state and input\n",
    "    \"\"\"\n",
    "    # layer iteration\n",
    "    for l in range(len(conv_params[0])):\n",
    "        # RY layer\n",
    "        # height iteration\n",
    "        for i in range(3):\n",
    "            # width iteration\n",
    "            for j in range(3):\n",
    "                qml.RY((conv_params[0][l][3*i+j] * inputs[i, j] + conv_params[1][l][3*i+j]), wires=(3*i+j))\n",
    "    \n",
    "        # entangling layer\n",
    "        for i in range(9):\n",
    "            if i != (9-1):\n",
    "                qml.CNOT(wires=[i, i+1])\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0) @ qml.PauliZ(1) @ qml.PauliZ(2) @ qml.PauliZ(3) @ qml.PauliZ(4) @ qml.PauliZ(5) @ qml.PauliZ(6) @ qml.PauliZ(7) @ qml.PauliZ(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((2, 1, 9))\n",
    "q_conv(a, X_train[0, 0:3, 0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((2, 1, 9))\n",
    "q_fc(a, X_train[0, 0, 0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_weights(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(class_weights, self).__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=w_init(shape=(1, 2), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return (inputs * self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image, size = 27 x 27\n",
    "X = tf.keras.Input(shape=(27,27), name='Input_Layer')\n",
    "\n",
    "\n",
    "# Specs for Conv\n",
    "c_filter = 3\n",
    "c_strides = 2\n",
    "\n",
    "\n",
    "# First Quantum Conv Layer, trainable params = 18*L, output size = 13 x 13\n",
    "num_conv_layer_1 = 2\n",
    "q_conv_layer_1 = qml.qnn.KerasLayer(q_conv, {\"conv_params\": (2, num_conv_layer_1, 9)}, output_dim=(1), name='Quantum_Conv_Layer_1')\n",
    "size_1 = int(1+(X.shape[1]-c_filter)/c_strides)\n",
    "q_conv_layer_1_list = []\n",
    "# height iteration\n",
    "for i in range(size_1):\n",
    "    # width iteration\n",
    "    for j in range(size_1):\n",
    "        temp = q_conv_layer_1(X[:, 2*i:2*(i+1)+1, 2*j:2*(j+1)+1])\n",
    "        temp = tf.keras.layers.Reshape((1,))(temp)\n",
    "        q_conv_layer_1_list += [temp]\n",
    "concat_layer_1 = tf.keras.layers.Concatenate(axis=1)(q_conv_layer_1_list)\n",
    "reshape_layer_1 = tf.keras.layers.Reshape((size_1, size_1))(concat_layer_1)\n",
    "\n",
    "\n",
    "# Second Quantum Conv Layer, trainable params = 18*L, output size = 6 x 6\n",
    "num_conv_layer_2 = 2\n",
    "q_conv_layer_2 = qml.qnn.KerasLayer(q_conv, {\"conv_params\": (2, num_conv_layer_2, 9)}, output_dim=(1), name='Quantum_Conv_Layer_2')\n",
    "size_2 = int(1+(reshape_layer_1.shape[1]-c_filter)/c_strides)\n",
    "q_conv_layer_2_list = []\n",
    "# height iteration\n",
    "for i in range(size_2):\n",
    "    # width iteration\n",
    "    for j in range(size_2):\n",
    "        temp = q_conv_layer_2(reshape_layer_1[:, 2*i:2*(i+1)+1, 2*j:2*(j+1)+1])\n",
    "        temp = tf.keras.layers.Reshape((1,))(temp)\n",
    "        q_conv_layer_2_list += [temp]\n",
    "concat_layer_2 = tf.keras.layers.Concatenate(axis=1)(q_conv_layer_2_list)\n",
    "reshape_layer_2 = tf.keras.layers.Reshape((size_2, size_2, 1))(concat_layer_2)\n",
    "\n",
    "\n",
    "# Max Pooling Layer, output size = 9\n",
    "max_pool_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, name='Max_Pool_Layer')(reshape_layer_2)\n",
    "reshape_layer_3 = tf.keras.layers.Reshape((9,))(max_pool_layer)\n",
    "\n",
    "\n",
    "# Quantum FC Layer, trainable params = 18*L*n_class + 2, output size = 2\n",
    "num_fc_layer = 1\n",
    "q_fc_layer_0 = qml.qnn.KerasLayer(q_fc, {\"params\": (2, num_fc_layer, 9)}, output_dim=2)(reshape_layer_3)\n",
    "q_fc_layer_1 = qml.qnn.KerasLayer(q_fc, {\"params\": (2, num_fc_layer, 9)}, output_dim=2)(reshape_layer_3)\n",
    "q_fc_layer_2 = qml.qnn.KerasLayer(q_fc, {\"params\": (2, num_fc_layer, 9)}, output_dim=2)(reshape_layer_3)\n",
    "q_fc_layer_3 = qml.qnn.KerasLayer(q_fc, {\"params\": (2, num_fc_layer, 9)}, output_dim=2)(reshape_layer_3)\n",
    "\n",
    "# Alpha Layer\n",
    "alpha_layer_0 = class_weights()(q_fc_layer_0)\n",
    "alpha_layer_1 = class_weights()(q_fc_layer_1)\n",
    "alpha_layer_2 = class_weights()(q_fc_layer_2)\n",
    "alpha_layer_3 = class_weights()(q_fc_layer_3)\n",
    "\n",
    "model = tf.keras.Model(inputs=X, outputs=[alpha_layer_0, alpha_layer_1, alpha_layer_2, alpha_layer_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y_train_dict)):\n",
    "    new_key = model.layers[len(model.layers)-4+i].name\n",
    "    old_key = \"Y\" + str(i)\n",
    "    \n",
    "    Y_train_dict[new_key] = Y_train_dict.pop(old_key)\n",
    "    Y_test_dict[new_key] = Y_test_dict.pop(old_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weights': array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_1': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_2': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_3': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weights': array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_1': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_2': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]], dtype=float32),\n",
       " 'class_weights_3': array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       " array([[-0.00600334, -0.00034606],\n",
       "        [-0.00600469, -0.00034166],\n",
       "        [-0.0060025 , -0.00034878],\n",
       "        [-0.006003  , -0.00034714],\n",
       "        [-0.00599951, -0.00035846]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       " array([[ 2.2392379e-02, -1.1029702e-05],\n",
       "        [ 2.2394637e-02, -8.3743453e-06],\n",
       "        [ 2.2394801e-02, -8.1811704e-06],\n",
       "        [ 2.2392794e-02, -1.0541782e-05],\n",
       "        [ 2.2394311e-02, -8.7582230e-06]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       " array([[ 9.8464414e-02, -2.7805081e-05],\n",
       "        [ 9.8455302e-02, -3.2004948e-05],\n",
       "        [ 9.8460138e-02, -2.9776358e-05],\n",
       "        [ 9.8461285e-02, -2.9245010e-05],\n",
       "        [ 9.8464921e-02, -2.7571534e-05]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       " array([[ 0.06726237, -0.00438467],\n",
       "        [ 0.06724458, -0.00439067],\n",
       "        [ 0.06715995, -0.00441923],\n",
       "        [ 0.06731631, -0.00436647],\n",
       "        [ 0.06694063, -0.00449323]], dtype=float32)>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[0:5, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weights': 'mse', 'class_weights_1': 'mse', 'class_weights_2': 'mse', 'class_weights_3': 'mse'}\n"
     ]
    }
   ],
   "source": [
    "losses = {\n",
    "    model.layers[len(model.layers)-4+0].name: \"mse\",\n",
    "    model.layers[len(model.layers)-4+1].name: \"mse\",\n",
    "    model.layers[len(model.layers)-4+2].name: \"mse\",\n",
    "    model.layers[len(model.layers)-4+3].name: \"mse\"\n",
    "}\n",
    "\n",
    "#lossWeights = {\"Y0\": 1.0, \"Y1\": 1.0, \"Y2\": 1.0, \"Y3\": 1.0}\n",
    "\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "model.compile(opt, loss=losses, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_val_acc = tf.keras.callbacks.ModelCheckpoint(filepath=\"./Model/QConv_4class_Branch_1stmodel_val_acc.hdf5\",\n",
    "                monitor='val_accuracy', verbose=1, save_weights_only=True, save_best_only=True, mode='max')\n",
    "\n",
    "cp_val_loss = tf.keras.callbacks.ModelCheckpoint(filepath=\"./Model/QConv_4class_Branch_1stmodel_val_loss.hdf5\",\n",
    "                monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 26368s 1054s/step - loss: 1.3849 - class_weights_loss: 0.3384 - class_weights_1_loss: 0.3380 - class_weights_2_loss: 0.3469 - class_weights_3_loss: 0.3616 - class_weights_accuracy: 0.5893 - class_weights_1_accuracy: 0.5078 - class_weights_2_accuracy: 0.4854 - class_weights_3_accuracy: 0.4369 - val_loss: 0.8346 - val_class_weights_loss: 0.2113 - val_class_weights_1_loss: 0.2201 - val_class_weights_2_loss: 0.2040 - val_class_weights_3_loss: 0.1993 - val_class_weights_accuracy: 0.7500 - val_class_weights_1_accuracy: 0.7500 - val_class_weights_2_accuracy: 0.7500 - val_class_weights_3_accuracy: 0.7500\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.83459, saving model to ./Model/QConv_4class_Branch_1stmodel_val_loss.hdf5\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 26508s 1061s/step - loss: 0.8321 - class_weights_loss: 0.2031 - class_weights_1_loss: 0.2105 - class_weights_2_loss: 0.2159 - class_weights_3_loss: 0.2027 - class_weights_accuracy: 0.7474 - class_weights_1_accuracy: 0.7445 - class_weights_2_accuracy: 0.7379 - class_weights_3_accuracy: 0.7668 - val_loss: 0.7796 - val_class_weights_loss: 0.1990 - val_class_weights_1_loss: 0.1904 - val_class_weights_2_loss: 0.2007 - val_class_weights_3_loss: 0.1895 - val_class_weights_accuracy: 0.7500 - val_class_weights_1_accuracy: 0.7500 - val_class_weights_2_accuracy: 0.7500 - val_class_weights_3_accuracy: 0.7500\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss improved from 0.83459 to 0.77959, saving model to ./Model/QConv_4class_Branch_1stmodel_val_loss.hdf5\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 27041s 1083s/step - loss: 0.7694 - class_weights_loss: 0.1970 - class_weights_1_loss: 0.1982 - class_weights_2_loss: 0.1928 - class_weights_3_loss: 0.1815 - class_weights_accuracy: 0.7506 - class_weights_1_accuracy: 0.7298 - class_weights_2_accuracy: 0.7526 - class_weights_3_accuracy: 0.7670 - val_loss: 0.7434 - val_class_weights_loss: 0.1744 - val_class_weights_1_loss: 0.1944 - val_class_weights_2_loss: 0.1928 - val_class_weights_3_loss: 0.1817 - val_class_weights_accuracy: 0.7500 - val_class_weights_1_accuracy: 0.7500 - val_class_weights_2_accuracy: 0.7500 - val_class_weights_3_accuracy: 0.7500\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss improved from 0.77959 to 0.74339, saving model to ./Model/QConv_4class_Branch_1stmodel_val_loss.hdf5\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 27040s 1082s/step - loss: 0.7334 - class_weights_loss: 0.1754 - class_weights_1_loss: 0.1780 - class_weights_2_loss: 0.1930 - class_weights_3_loss: 0.1870 - class_weights_accuracy: 0.7619 - class_weights_1_accuracy: 0.7571 - class_weights_2_accuracy: 0.7554 - class_weights_3_accuracy: 0.7547 - val_loss: 0.6471 - val_class_weights_loss: 0.1735 - val_class_weights_1_loss: 0.0912 - val_class_weights_2_loss: 0.2067 - val_class_weights_3_loss: 0.1757 - val_class_weights_accuracy: 0.7500 - val_class_weights_1_accuracy: 0.9150 - val_class_weights_2_accuracy: 0.7500 - val_class_weights_3_accuracy: 0.7500\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss improved from 0.74339 to 0.64713, saving model to ./Model/QConv_4class_Branch_1stmodel_val_loss.hdf5\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 27235s 1092s/step - loss: 0.7044 - class_weights_loss: 0.1810 - class_weights_1_loss: 0.1280 - class_weights_2_loss: 0.2022 - class_weights_3_loss: 0.1933 - class_weights_accuracy: 0.7400 - class_weights_1_accuracy: 0.8351 - class_weights_2_accuracy: 0.7487 - class_weights_3_accuracy: 0.7488 - val_loss: 0.6609 - val_class_weights_loss: 0.1887 - val_class_weights_1_loss: 0.0860 - val_class_weights_2_loss: 0.1865 - val_class_weights_3_loss: 0.1998 - val_class_weights_accuracy: 0.7500 - val_class_weights_1_accuracy: 0.9050 - val_class_weights_2_accuracy: 0.7500 - val_class_weights_3_accuracy: 0.7500\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve from 0.64713\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 27919s 1119s/step - loss: 0.6460 - class_weights_loss: 0.1636 - class_weights_1_loss: 0.1006 - class_weights_2_loss: 0.1874 - class_weights_3_loss: 0.1945 - class_weights_accuracy: 0.7681 - class_weights_1_accuracy: 0.8650 - class_weights_2_accuracy: 0.7450 - class_weights_3_accuracy: 0.7519 - val_loss: 0.6132 - val_class_weights_loss: 0.1604 - val_class_weights_1_loss: 0.0800 - val_class_weights_2_loss: 0.1766 - val_class_weights_3_loss: 0.1963 - val_class_weights_accuracy: 0.7950 - val_class_weights_1_accuracy: 0.9150 - val_class_weights_2_accuracy: 0.7500 - val_class_weights_3_accuracy: 0.7500\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_loss improved from 0.64713 to 0.61323, saving model to ./Model/QConv_4class_Branch_1stmodel_val_loss.hdf5\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 27564s 1102s/step - loss: 0.5974 - class_weights_loss: 0.1505 - class_weights_1_loss: 0.0906 - class_weights_2_loss: 0.1807 - class_weights_3_loss: 0.1756 - class_weights_accuracy: 0.7855 - class_weights_1_accuracy: 0.8799 - class_weights_2_accuracy: 0.7456 - class_weights_3_accuracy: 0.7520 - val_loss: 0.6559 - val_class_weights_loss: 0.1845 - val_class_weights_1_loss: 0.1070 - val_class_weights_2_loss: 0.1937 - val_class_weights_3_loss: 0.1707 - val_class_weights_accuracy: 0.7350 - val_class_weights_1_accuracy: 0.8450 - val_class_weights_2_accuracy: 0.7500 - val_class_weights_3_accuracy: 0.7750\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_loss did not improve from 0.61323\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 26982s 1081s/step - loss: 0.5894 - class_weights_loss: 0.1480 - class_weights_1_loss: 0.1082 - class_weights_2_loss: 0.1642 - class_weights_3_loss: 0.1690 - class_weights_accuracy: 0.8067 - class_weights_1_accuracy: 0.8564 - class_weights_2_accuracy: 0.7722 - class_weights_3_accuracy: 0.7372 - val_loss: 0.5626 - val_class_weights_loss: 0.1270 - val_class_weights_1_loss: 0.0770 - val_class_weights_2_loss: 0.2003 - val_class_weights_3_loss: 0.1583 - val_class_weights_accuracy: 0.8150 - val_class_weights_1_accuracy: 0.9050 - val_class_weights_2_accuracy: 0.7200 - val_class_weights_3_accuracy: 0.7750\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_loss improved from 0.61323 to 0.56259, saving model to ./Model/QConv_4class_Branch_1stmodel_val_loss.hdf5\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 27345s 1096s/step - loss: 0.5376 - class_weights_loss: 0.1169 - class_weights_1_loss: 0.0886 - class_weights_2_loss: 0.1675 - class_weights_3_loss: 0.1646 - class_weights_accuracy: 0.8418 - class_weights_1_accuracy: 0.8722 - class_weights_2_accuracy: 0.7583 - class_weights_3_accuracy: 0.7719 - val_loss: 0.5090 - val_class_weights_loss: 0.1242 - val_class_weights_1_loss: 0.0430 - val_class_weights_2_loss: 0.1753 - val_class_weights_3_loss: 0.1665 - val_class_weights_accuracy: 0.8100 - val_class_weights_1_accuracy: 0.9550 - val_class_weights_2_accuracy: 0.7200 - val_class_weights_3_accuracy: 0.7500\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00009: val_loss improved from 0.56259 to 0.50899, saving model to ./Model/QConv_4class_Branch_1stmodel_val_loss.hdf5\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 27424s 1097s/step - loss: 0.5247 - class_weights_loss: 0.1364 - class_weights_1_loss: 0.0739 - class_weights_2_loss: 0.1603 - class_weights_3_loss: 0.1542 - class_weights_accuracy: 0.8150 - class_weights_1_accuracy: 0.9018 - class_weights_2_accuracy: 0.7686 - class_weights_3_accuracy: 0.7702 - val_loss: 0.5167 - val_class_weights_loss: 0.1149 - val_class_weights_1_loss: 0.0568 - val_class_weights_2_loss: 0.2041 - val_class_weights_3_loss: 0.1408 - val_class_weights_accuracy: 0.8450 - val_class_weights_1_accuracy: 0.9300 - val_class_weights_2_accuracy: 0.7500 - val_class_weights_3_accuracy: 0.8100\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss did not improve from 0.50899\n"
     ]
    }
   ],
   "source": [
    "H = model.fit(X_train, Y_train_dict, epochs=10, batch_size=32,\n",
    "              validation_data=(X_test, Y_test_dict), verbose=1, initial_epoch=0,\n",
    "              callbacks=[cp_val_acc, cp_val_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.0673325061798096,\n",
       "  0.8125658631324768,\n",
       "  0.76201993227005,\n",
       "  0.7202985286712646,\n",
       "  0.7074598670005798,\n",
       "  0.6407968997955322,\n",
       "  0.611415684223175,\n",
       "  0.5668624639511108,\n",
       "  0.5290957093238831,\n",
       "  0.5243417620658875],\n",
       " 'class_weights_loss': [0.25470492243766785,\n",
       "  0.1992626041173935,\n",
       "  0.19176846742630005,\n",
       "  0.1843419075012207,\n",
       "  0.1835613250732422,\n",
       "  0.16402918100357056,\n",
       "  0.15690213441848755,\n",
       "  0.1330072432756424,\n",
       "  0.124656543135643,\n",
       "  0.1233828142285347],\n",
       " 'class_weights_1_loss': [0.2554158568382263,\n",
       "  0.19970768690109253,\n",
       "  0.18830129504203796,\n",
       "  0.15004493296146393,\n",
       "  0.12540878355503082,\n",
       "  0.10233556479215622,\n",
       "  0.0978090763092041,\n",
       "  0.09619536995887756,\n",
       "  0.07575585693120956,\n",
       "  0.07780732959508896],\n",
       " 'class_weights_2_loss': [0.26890334486961365,\n",
       "  0.2077968418598175,\n",
       "  0.19130802154541016,\n",
       "  0.19840297102928162,\n",
       "  0.1978829950094223,\n",
       "  0.18151085078716278,\n",
       "  0.18296970427036285,\n",
       "  0.1697700470685959,\n",
       "  0.16564609110355377,\n",
       "  0.16503815352916718],\n",
       " 'class_weights_3_loss': [0.28830820322036743,\n",
       "  0.20579880475997925,\n",
       "  0.19064213335514069,\n",
       "  0.18750879168510437,\n",
       "  0.20060674846172333,\n",
       "  0.19292137026786804,\n",
       "  0.17373472452163696,\n",
       "  0.1678898185491562,\n",
       "  0.16303710639476776,\n",
       "  0.1581135243177414],\n",
       " 'class_weights_accuracy': [0.6850000023841858,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.7537500262260437,\n",
       "  0.7724999785423279,\n",
       "  0.7825000286102295,\n",
       "  0.8324999809265137,\n",
       "  0.8262500166893005,\n",
       "  0.8337500095367432],\n",
       " 'class_weights_1_accuracy': [0.6587499976158142,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.7950000166893005,\n",
       "  0.8337500095367432,\n",
       "  0.862500011920929,\n",
       "  0.8712499737739563,\n",
       "  0.8675000071525574,\n",
       "  0.9037500023841858,\n",
       "  0.8987500071525574],\n",
       " 'class_weights_2_accuracy': [0.6200000047683716,\n",
       "  0.7475000023841858,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.7462499737739563,\n",
       "  0.75,\n",
       "  0.7612500190734863,\n",
       "  0.7574999928474426],\n",
       " 'class_weights_3_accuracy': [0.6000000238418579,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.7412499785423279,\n",
       "  0.737500011920929,\n",
       "  0.7537500262260437,\n",
       "  0.7450000047683716,\n",
       "  0.7649999856948853,\n",
       "  0.7599999904632568],\n",
       " 'val_loss': [0.8345871567726135,\n",
       "  0.7795928120613098,\n",
       "  0.7433924674987793,\n",
       "  0.6471298336982727,\n",
       "  0.6608887314796448,\n",
       "  0.6132335662841797,\n",
       "  0.6559077501296997,\n",
       "  0.562591552734375,\n",
       "  0.5089918375015259,\n",
       "  0.5167287588119507],\n",
       " 'val_class_weights_loss': [0.2112870216369629,\n",
       "  0.19904175400733948,\n",
       "  0.17444390058517456,\n",
       "  0.17352108657360077,\n",
       "  0.18868131935596466,\n",
       "  0.16035304963588715,\n",
       "  0.18447519838809967,\n",
       "  0.12697510421276093,\n",
       "  0.12424743920564651,\n",
       "  0.1149401068687439],\n",
       " 'val_class_weights_1_loss': [0.22005362808704376,\n",
       "  0.19038927555084229,\n",
       "  0.19441759586334229,\n",
       "  0.0912315621972084,\n",
       "  0.08600538223981857,\n",
       "  0.08001520484685898,\n",
       "  0.10702023655176163,\n",
       "  0.07699659466743469,\n",
       "  0.04297344759106636,\n",
       "  0.056838035583496094],\n",
       " 'val_class_weights_2_loss': [0.20395156741142273,\n",
       "  0.200700581073761,\n",
       "  0.19283190369606018,\n",
       "  0.2066829651594162,\n",
       "  0.1864515095949173,\n",
       "  0.17660874128341675,\n",
       "  0.1937168687582016,\n",
       "  0.20033234357833862,\n",
       "  0.1752968728542328,\n",
       "  0.20414027571678162],\n",
       " 'val_class_weights_3_loss': [0.19929492473602295,\n",
       "  0.18946118652820587,\n",
       "  0.18169918656349182,\n",
       "  0.17569421231746674,\n",
       "  0.19975051283836365,\n",
       "  0.1962565779685974,\n",
       "  0.1706954389810562,\n",
       "  0.15828751027584076,\n",
       "  0.16647407412528992,\n",
       "  0.14081035554409027],\n",
       " 'val_class_weights_accuracy': [0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.7950000166893005,\n",
       "  0.7350000143051147,\n",
       "  0.8149999976158142,\n",
       "  0.8100000023841858,\n",
       "  0.8450000286102295],\n",
       " 'val_class_weights_1_accuracy': [0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.9150000214576721,\n",
       "  0.9049999713897705,\n",
       "  0.9150000214576721,\n",
       "  0.8450000286102295,\n",
       "  0.9049999713897705,\n",
       "  0.9549999833106995,\n",
       "  0.9300000071525574],\n",
       " 'val_class_weights_2_accuracy': [0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.7200000286102295,\n",
       "  0.7200000286102295,\n",
       "  0.75],\n",
       " 'val_class_weights_3_accuracy': [0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.75,\n",
       "  0.7749999761581421,\n",
       "  0.7749999761581421,\n",
       "  0.75,\n",
       "  0.8100000023841858]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'model/Quantum_Conv_Layer_1/conv_params:0' shape=(2, 2, 9) dtype=float32, numpy=\n",
       " array([[[ 1.2869661e-01,  7.4135363e-01, -3.0460116e-03,  9.0277719e-01,\n",
       "          -7.8009658e-02, -1.4513086e-01, -1.4736656e+00, -4.1665393e-01,\n",
       "           1.8109004e+00],\n",
       "         [-3.3571446e-01, -1.4859587e-01, -1.8293101e+00,  2.0287144e-01,\n",
       "          -4.2460194e-01, -3.3956528e-01, -4.6123242e-01,  1.9535863e-01,\n",
       "           9.8429596e-01]],\n",
       " \n",
       "        [[-2.1573634e+00,  1.0368041e+00,  1.5500332e+00,  3.6416778e-01,\n",
       "           7.9319847e-01, -3.3785913e+00, -1.4334810e+00,  1.8856882e+00,\n",
       "          -4.3846551e-01],\n",
       "         [-9.1071910e-01,  3.1239581e-01, -1.3975484e+00,  3.4865671e-01,\n",
       "          -3.1961536e-01,  4.4947404e-01, -1.9606891e+00,  2.3715436e-01,\n",
       "           8.9548969e-01]]], dtype=float32)>,\n",
       " <tf.Variable 'model/Quantum_Conv_Layer_2/conv_params:0' shape=(2, 2, 9) dtype=float32, numpy=\n",
       " array([[[ 3.4925842e-01, -5.6708436e+00, -1.9404861e+00,  1.6397353e+00,\n",
       "          -2.9650667e+00,  2.2565560e+00,  3.8740587e+00, -2.7107643e-03,\n",
       "           1.7356348e+00],\n",
       "         [-2.7163332e+00,  3.9046150e-01,  2.1589890e+00,  5.1092440e-01,\n",
       "           1.3031520e+00,  4.8888689e-01, -1.4238943e+00, -1.2235752e-01,\n",
       "           1.3342757e+00]],\n",
       " \n",
       "        [[ 4.1802579e-01,  8.4332108e-01, -5.3183663e-01,  3.5747871e-01,\n",
       "          -4.5673713e-01,  2.7017541e+00, -3.7721741e+00, -4.9070220e-02,\n",
       "           6.0611880e-01],\n",
       "         [-9.1601098e-01,  1.6563272e-01,  4.1952944e-01, -1.0007954e-01,\n",
       "           2.7106845e-01, -3.3885369e-01, -3.7635034e-01,  1.7592680e-01,\n",
       "           5.7793677e-01]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[ 0.23026957,  1.1988934 , -2.6632056 ,  2.7058947 ,\n",
       "           2.407819  , -2.4749997 , -1.6144711 ,  1.6868379 ,\n",
       "          -0.54101574]],\n",
       " \n",
       "        [[ 0.18391116,  1.0950897 ,  0.1846029 ,  0.67919457,\n",
       "           1.1914817 , -0.34353888, -0.04270522,  1.2881347 ,\n",
       "           0.44612843]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_1/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[-0.30491176,  0.3898287 ,  1.0112525 ,  0.30286118,\n",
       "          -2.4130082 ,  0.12776785, -0.01559066, -2.8789024 ,\n",
       "          -0.1322919 ]],\n",
       " \n",
       "        [[ 0.5133039 , -1.0219164 ,  1.4968314 ,  1.2127702 ,\n",
       "          -1.2039986 ,  0.2895342 , -0.60191005,  0.16187583,\n",
       "           0.23189166]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_2/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[-0.10402252,  1.576955  ,  1.5411117 , -1.5873302 ,\n",
       "          -1.8431503 , -1.0710971 , -0.26119778,  0.28042018,\n",
       "          -0.28840777]],\n",
       " \n",
       "        [[ 0.44976795,  0.66184056,  0.13290721, -0.1990643 ,\n",
       "           1.6494706 , -0.46990612, -0.3065016 ,  0.48001087,\n",
       "          -0.08404096]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_3/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[ 0.1789683 ,  0.7664196 , -1.3100542 ,  1.018131  ,\n",
       "           1.4095626 , -0.00675754,  0.11128075,  1.029676  ,\n",
       "          -0.48152244]],\n",
       " \n",
       "        [[ 0.04842091,  0.5135664 , -0.17360954, -0.18402573,\n",
       "           0.95090616, -0.04112992,  0.58352494,  1.6469798 ,\n",
       "          -0.53215635]]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[0.910227 , 1.0887856]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[0.9304982, 1.0913638]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[0.85587573, 1.0654645 ]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[0.9728808 , 0.98372984]], dtype=float32)>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2222222222222223"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1L QConv1, 1L QConv2, 1L QFC, no entangler at all\n",
    "# 1 epoch = ... jam\n",
    "8000/(60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.322222222222222"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "26360/(60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'model/Quantum_Conv_Layer_1/conv_params:0' shape=(2, 2, 9) dtype=float32, numpy=\n",
       " array([[[ 0.30478922,  0.24122563,  1.2013984 ,  0.8962295 ,\n",
       "           2.155613  ,  1.808066  , -0.6777786 , -1.3539367 ,\n",
       "           0.46882528],\n",
       "         [ 0.10804682,  0.4899469 , -1.4487113 ,  0.18007451,\n",
       "           0.21117014, -0.07102177,  0.22456087,  0.19595939,\n",
       "           0.620559  ]],\n",
       " \n",
       "        [[ 0.08490325, -0.46300295,  0.88712513,  0.21560192,\n",
       "           0.68917143, -1.3093163 ,  1.0160891 , -0.17013887,\n",
       "           0.09957722],\n",
       "         [ 0.08793638, -0.0810757 , -0.3338206 ,  0.5029927 ,\n",
       "           0.46003294,  0.47570366, -0.18548904, -0.2648427 ,\n",
       "          -0.0655445 ]]], dtype=float32)>,\n",
       " <tf.Variable 'model/Quantum_Conv_Layer_2/conv_params:0' shape=(2, 2, 9) dtype=float32, numpy=\n",
       " array([[[ 2.7642950e-01,  2.3297124e+00, -7.7425838e-01,  4.8847955e-01,\n",
       "           4.3419965e-02, -3.3615255e-01, -1.0063299e+00,  2.2314610e+00,\n",
       "           9.1715485e-01],\n",
       "         [-4.1352111e-01,  3.0436099e-02, -1.2301649e+00,  1.7263293e-03,\n",
       "          -1.5698449e-01,  4.4744748e-01,  1.2136365e+00,  2.7647603e-01,\n",
       "           1.0283145e+00]],\n",
       " \n",
       "        [[-3.3875754e-01,  1.0402726e+00, -4.2845064e-01,  7.4869722e-02,\n",
       "           3.8802050e-02,  3.3155876e-01, -7.6660907e-01,  3.3909407e-01,\n",
       "           3.5294789e-01],\n",
       "         [ 6.6214994e-02, -1.3985926e-01,  9.4863945e-01, -1.1182010e-01,\n",
       "           2.7276468e-01,  3.9622694e-01,  3.1741151e-01, -2.2376621e-01,\n",
       "           3.0038670e-01]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[-0.05643808, -0.3834348 ,  1.3783973 ,  1.8028375 ,\n",
       "           2.4020152 ,  3.265065  ,  0.04925077,  0.18717681,\n",
       "          -0.15576944]],\n",
       " \n",
       "        [[ 0.0552775 ,  0.83352816,  0.51252973,  0.67993635,\n",
       "           1.538679  ,  0.5075311 ,  1.462727  ,  0.28211135,\n",
       "          -0.18711801]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_1/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[ 0.5008777 , -1.3495312 , -0.5218247 ,  1.51395   ,\n",
       "           0.70898056,  1.331641  ,  0.75333315,  1.1442982 ,\n",
       "          -0.283115  ]],\n",
       " \n",
       "        [[ 0.23336929,  1.3037012 , -0.16543525, -0.8135664 ,\n",
       "           0.5298867 , -0.08688857, -0.40758485,  1.3480728 ,\n",
       "          -0.06701605]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_2/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[ 0.20852552, -0.92169833,  0.20204262, -1.4812163 ,\n",
       "           0.00889985, -1.5283754 , -0.8842213 , -2.125618  ,\n",
       "          -0.2756645 ]],\n",
       " \n",
       "        [[ 0.19089271, -1.2583857 , -0.05586167, -0.65264225,\n",
       "           0.72431535, -0.6168651 , -0.59993476, -2.472832  ,\n",
       "           0.120191  ]]], dtype=float32)>,\n",
       " <tf.Variable 'model/keras_layer_3/params:0' shape=(2, 1, 9) dtype=float32, numpy=\n",
       " array([[[-0.30617303,  0.06194295, -0.42034343, -1.888615  ,\n",
       "          -2.2937555 ,  0.68672144,  1.2960382 , -1.1311744 ,\n",
       "          -0.19152352]],\n",
       " \n",
       "        [[-0.12496919, -0.75718635, -0.21456823, -0.07930091,\n",
       "          -0.44249678, -0.28310478,  0.76265246, -1.462515  ,\n",
       "           0.08680444]]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[0.9889597, 1.064973 ]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1.0520185, 1.0743465]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1.0430095, 1.0347432]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1.0084324, 1.0561559]], dtype=float32)>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_6_epoch_weights = model.weights\n",
    "first_6_epoch_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.9413223266601562,\n",
       "  0.5048812627792358,\n",
       "  0.4011978209018707,\n",
       "  0.347080796957016,\n",
       "  0.31995534896850586,\n",
       "  0.29129528999328613],\n",
       " 'class_weights_loss': [0.2251260131597519,\n",
       "  0.1090371310710907,\n",
       "  0.07864071428775787,\n",
       "  0.0647929459810257,\n",
       "  0.05809621885418892,\n",
       "  0.056281398981809616],\n",
       " 'class_weights_1_loss': [0.21691031754016876,\n",
       "  0.09565035998821259,\n",
       "  0.06009742617607117,\n",
       "  0.043785590678453445,\n",
       "  0.03979836404323578,\n",
       "  0.03735021501779556],\n",
       " 'class_weights_2_loss': [0.2575957775115967,\n",
       "  0.16418935358524323,\n",
       "  0.1520228236913681,\n",
       "  0.13327646255493164,\n",
       "  0.12420327216386795,\n",
       "  0.10296647995710373],\n",
       " 'class_weights_3_loss': [0.24169006943702698,\n",
       "  0.13600443303585052,\n",
       "  0.11043684929609299,\n",
       "  0.10522573441267014,\n",
       "  0.0978575050830841,\n",
       "  0.09469721466302872],\n",
       " 'class_weights_accuracy': [0.7325000166893005,\n",
       "  0.862500011920929,\n",
       "  0.9137499928474426,\n",
       "  0.9212499856948853,\n",
       "  0.9337499737739563,\n",
       "  0.9449999928474426],\n",
       " 'class_weights_1_accuracy': [0.7612500190734863,\n",
       "  0.9075000286102295,\n",
       "  0.9412500262260437,\n",
       "  0.9574999809265137,\n",
       "  0.9674999713897705,\n",
       "  0.9624999761581421],\n",
       " 'class_weights_2_accuracy': [0.6524999737739563,\n",
       "  0.7774999737739563,\n",
       "  0.8012499809265137,\n",
       "  0.8399999737739563,\n",
       "  0.8399999737739563,\n",
       "  0.8700000047683716],\n",
       " 'class_weights_3_accuracy': [0.7099999785423279,\n",
       "  0.7887499928474426,\n",
       "  0.8500000238418579,\n",
       "  0.8650000095367432,\n",
       "  0.8712499737739563,\n",
       "  0.8762500286102295],\n",
       " 'val_loss': [0.6251590847969055,\n",
       "  0.46162113547325134,\n",
       "  0.4657244384288788,\n",
       "  0.39843636751174927,\n",
       "  0.3622923791408539,\n",
       "  0.30785781145095825],\n",
       " 'val_class_weights_loss': [0.1505269557237625,\n",
       "  0.09454558044672012,\n",
       "  0.08041784167289734,\n",
       "  0.060097817331552505,\n",
       "  0.04866035282611847,\n",
       "  0.046398259699344635],\n",
       " 'val_class_weights_1_loss': [0.13554787635803223,\n",
       "  0.06550124287605286,\n",
       "  0.09156784415245056,\n",
       "  0.06080688536167145,\n",
       "  0.057105377316474915,\n",
       "  0.02648923173546791],\n",
       " 'val_class_weights_2_loss': [0.18397700786590576,\n",
       "  0.17508715391159058,\n",
       "  0.17087066173553467,\n",
       "  0.15946416556835175,\n",
       "  0.1398959755897522,\n",
       "  0.12513935565948486],\n",
       " 'val_class_weights_3_loss': [0.15510722994804382,\n",
       "  0.12648716568946838,\n",
       "  0.12286806106567383,\n",
       "  0.11806746572256088,\n",
       "  0.1166306659579277,\n",
       "  0.10983096063137054],\n",
       " 'val_class_weights_accuracy': [0.8199999928474426,\n",
       "  0.8949999809265137,\n",
       "  0.8899999856948853,\n",
       "  0.9350000023841858,\n",
       "  0.9399999976158142,\n",
       "  0.9599999785423279],\n",
       " 'val_class_weights_1_accuracy': [0.8149999976158142,\n",
       "  0.9549999833106995,\n",
       "  0.8700000047683716,\n",
       "  0.9399999976158142,\n",
       "  0.9449999928474426,\n",
       "  0.9750000238418579],\n",
       " 'val_class_weights_2_accuracy': [0.7450000047683716,\n",
       "  0.7649999856948853,\n",
       "  0.7649999856948853,\n",
       "  0.7900000214576721,\n",
       "  0.7799999713897705,\n",
       "  0.800000011920929],\n",
       " 'val_class_weights_3_accuracy': [0.7900000214576721,\n",
       "  0.8050000071525574,\n",
       "  0.8199999928474426,\n",
       "  0.8199999928474426,\n",
       "  0.824999988079071,\n",
       "  0.824999988079071]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_6_epoch_hist = H.history\n",
    "first_6_epoch_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
